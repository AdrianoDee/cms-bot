#!/bin/sh -ex

function filter_failed_comparison(){
  if [ -f $1/index.html ] ; then
    if [ $(grep 'Skipped:\|Null:\|Fail:' $1/index.html | wc -l) -gt 0 ] ; then
      echo "Keeping workflow: $1"
    else
      touch $1/.deleteme 
    fi
  fi
}

function wait_dqm_comp(){
  while true ; do
    djobs=0
    if [ "${DQM_PID}" != "" ] ; then
      if [ $(ps -p "$DQM_PID" -o cmd | grep '/compareDQMOutput.py ' | wc -l) -gt 0 ] ; then
        djobs=$(pgrep -P $DQM_PID 2>/dev/null | wc -l)
      fi
      [ $djobs -gt 0 ] || DQM_PID=""
    fi
    let djobs=${djobs}+$(jobs -p | wc -l) || true
    if [ $djobs -lt ${NUM_PROC} ] ; then break ; fi
    sleep $1
  done
}

source $(dirname $0)/setup-pr-test-env.sh
TEST_FLAVOR_STR=""
UC_TEST_FLAVOR=$(echo ${TEST_FLAVOR} | tr '[a-z]' '[A-Z]')
GH_COMP_CONTEXT="comparison"
if [ "${TEST_FLAVOR}" != "" ] ; then
  GH_COMP_CONTEXT="${GH_COMP_CONTEXT}/${TEST_FLAVOR}"
  TEST_FLAVOR_STR="_${UC_TEST_FLAVOR}"
fi

NUM_PROC=$(nproc)
export SCRAM_ARCH=$ARCHITECTURE
if [ "X$COMPARISON_ARCH" = "X" ] ; then COMPARISON_ARCH=$ARCHITECTURE; fi
cd $WORKSPACE
rm -rf $WORKSPACE/results $WORKSPACE/upload
JR_COMP_DIR=$WORKSPACE/results/JR-comparison
mkdir -p $WORKSPACE/upload ${JR_COMP_DIR} $WORKSPACE/data
rm -f $WORKSPACE/ALL_DONE
if [ "X$COMPARISON_RELEASE" = "X" ] ; then COMPARISON_RELEASE=$CMSSW_VERSION; fi
if [ "$REAL_ARCH" = "" ] ; then REAL_ARCH="-GenuineIntel"; fi
PR_NUM=$(echo ${PULL_REQUEST} | md5sum | sed 's| .*||' | cut -c27-33)
BASELINE_DIR=ib-baseline-tests/$COMPARISON_RELEASE/$COMPARISON_ARCH/$REAL_ARCH/matrix${TEST_FLAVOR}-results
PR_BASELINE_JOBDIR=pull-request-integration/${UPLOAD_UNIQ_ID}
PR_BASELINE_DIR=${PR_BASELINE_JOBDIR}/runTheMatrix${UC_TEST_FLAVOR}-results
JENKINS_ARTIFACTS_URL="https://cmssdt.cern.ch/SDT/jenkins-artifacts"
PR_RESULT_URL="${JENKINS_ARTIFACTS_URL}/${PR_BASELINE_JOBDIR}"
RESULTS_FILE=$WORKSPACE/comparison${UC_TEST_FLAVOR}.txt
COMP_UPLOAD_DIR="baseLineComparisons${UC_TEST_FLAVOR}/${COMPARISON_RELEASE}+${PR_NUM}/${BUILD_NUMBER}"
DAS_NON_CONSISTENT_WFS_FILE=wf_non_consistent_das.txt
MAPPING_FILE=wf_mapping.txt
ERRORS_FILE=wf_errors.txt

#Make sure Release baseline has been deployed
echo -n "Waiting for baseline .."
while [ ! -d ${CVMFS_ARTIFACT_DIR}/${BASELINE_DIR} ] ; do echo -n '.'; sleep 10 ; done
echo ''
if [ "${MATRIX_ARGS}" != "" ] ; then
 echo "${MATRIX_ARGS}"  | tr ';' '\n' | while IFS= read -r args; do
   args=$(echo "$args" | sed -e 's|.*\(-l *[^ ]*\).*|\1|;s|-|\\-|')
   echo -n "Waiting for \"$args\" .."
   while [ $(grep "$args" ${CVMFS_ARTIFACT_DIR}/${BASELINE_DIR}/workflows-*.done 2>/dev/null| wc -l) -eq 0 ] ; do
     echo -n '.'
     sleep 10
   done
   echo "Done: \"$args\""
 done
fi

mark_commit_status_all_prs "${GH_COMP_CONTEXT}" 'pending' -u "${BUILD_URL}" -d "Running" || true

if $DQM_COMPARISON_TEST ; then
  if ! which compareDQMOutput.py >/dev/null 2>&1 ; then
    DQM_COMPARISON_TEST=false
  fi
fi

#Build validateJR shared lib once
PID_WAIT=""
if [ "X$RUN_JR_COMP" = Xtrue ]; then
  mkdir -p $WORKSPACE/validateJR_lib
  pushd $WORKSPACE/validateJR_lib
    cp $CMS_BOT_DIR/comparisons/validate.C ./
    (echo -e "gSystem->Load(\"libFWCoreFWLite.so\");\n AutoLibraryLoader::enable();\n FWLiteEnabler::enable();\n .L validate.C+\n .qqqqqq" | root -l -b || true) &
    PID_WAIT="$!"
  popd
fi
#Build validateALT shared lib once
if [ "X$RUN_ALT_COMP" = Xtrue ]; then
  mkdir -p $WORKSPACE/validateALT_lib
  pushd $WORKSPACE/validateALT_lib
    cp $CMS_BOT_DIR/comparisons/compareValHists.C ./
    (echo -e "gROOT->SetStyle(\"Plain\");\n .L compareValHists.C+\n .qqqqqq" | root -l -b || true) &
    PID_WAIT="$! ${PID_WAIT}"
  popd
fi

cd $WORKSPACE/results
echo "Downloading Ref: `date`"
get_jenkins_artifacts ${BASELINE_DIR}/    $WORKSPACE/data/$COMPARISON_RELEASE/ || true
echo "Downloading PR: `date`"
get_jenkins_artifacts ${PR_BASELINE_DIR}/ $WORKSPACE/data/PR-${PR_NUM}/
echo "Done Downloading `date`"

(${CMSBOT_PYTHON_CMD} $CMS_BOT_DIR/logRootQA.py $WORKSPACE/data/${COMPARISON_RELEASE} $WORKSPACE/data/PR-${PR_NUM} ${JR_COMP_DIR} $WORKSPACE/results/default-comparison events >${JR_COMP_DIR}/logRootQA-events.log 2>&1 || true) &
PID_WAIT="$! ${PID_WAIT}"
cat $WORKSPACE/data/$COMPARISON_RELEASE/wf_mapping.*txt | sort | uniq > $WORKSPACE/$MAPPING_FILE
cat $WORKSPACE/data/$COMPARISON_RELEASE/wf_errors.*txt  | sort | uniq > $WORKSPACE/$ERRORS_FILE
cat $WORKSPACE/$MAPPING_FILE
cat $WORKSPACE/$ERRORS_FILE
WFS_WITH_ERRORS=''
for wf in ${WORKFLOWS_LIST//,/ }
do
  WF_PATH=`grep "^${wf}_" $WORKSPACE/$MAPPING_FILE` || true
  if [ "X$WF_PATH" = X ]; then
    ERR_DETAILS=`grep "$wf;" $WORKSPACE/$ERRORS_FILE` || true
    if [ "X$ERR_DETAILS" = X ]; then
      WFS_WITH_ERRORS=$ERR_DETAILS,$wf';1'
    else
      WFS_WITH_ERRORS=$ERR_DETAILS,$WFS_WITH_ERRORS
    fi
  else
    echo "Going to compare: $wf"
    echo $WF_PATH
    echo ""
    WORKFLOWS_TO_COMPARE=$WORKFLOWS_TO_COMPARE,$WF_PATH
  fi
done

#remove first ,
WORKFLOWS_TO_COMPARE=`echo $WORKFLOWS_TO_COMPARE | sed 's/^.//'`
echo $WORKFLOWS_TO_COMPARE
for WF in ${WORKFLOWS_TO_COMPARE//,/ }; do
  WF_DIR=`echo $WF | cut -d "/" -f1`
  WF_NUMBER=`echo $WF | cut -d'_' -f1`
  WF_FILE=$(basename $WF)

  mkdir -p $WORKSPACE/results/files/$WF_DIR
  ln -s $WORKSPACE/data/$COMPARISON_RELEASE/${WF} $WORKSPACE/results/files/$WF_DIR/$COMPARISON_RELEASE-$WF_FILE

  if [ -f $WORKSPACE/data/$COMPARISON_RELEASE/$WF_DIR/step1_dasquery.log ] ; then
    grep '/store/' $WORKSPACE/data/$COMPARISON_RELEASE/$WF_DIR/step1_dasquery.log > $WORKSPACE/results/files/$WF_DIR/$COMPARISON_RELEASE-step1_dasquery.log || true
  fi
  if [ -f $WORKSPACE/data/PR-${PR_NUM}/$WF ] ; then
    ln -s $WORKSPACE/data/PR-${PR_NUM}/$WF $WORKSPACE/results/files/$WF_DIR/$PR_NUM-$WF_FILE
  fi
  if [ -f $WORKSPACE/data/PR-${PR_NUM}/$WF_DIR/step1_dasquery.log ] ; then
    grep '/store/' $WORKSPACE/data/PR-${PR_NUM}/$WF_DIR/step1_dasquery.log > $WORKSPACE/results/files/$WF_DIR/$PR_NUM-step1_dasquery.log || true
  fi

  # check that the step1_dasquery.log files are correct.
  NUM_FILES=$(( `ls $WORKSPACE/results/files/$WF_DIR/*-step1_dasquery.log | wc -l` ))
  # if there is only one of them something is wrong, but if there is none is ok
  if [ "$NUM_FILES" -eq "1" ]; then
    WFS_WITH_DAS_INCONSISTENCY=$WF_NUMBER,$WFS_WITH_DAS_INCONSISTENCY
  elif [ "$NUM_FILES" -eq "2" ]; then
    PR_DAS_QUERY_LOG="$WORKSPACE/results/files/$WF_DIR/$PR_NUM-step1_dasquery.log"
    BASELINE_DAS_QUERY_LOG="$WORKSPACE/results/files/$WF_DIR/$COMPARISON_RELEASE-step1_dasquery.log"
    THEY_DIFFER=`diff -q "$PR_DAS_QUERY_LOG" "$BASELINE_DAS_QUERY_LOG" || true`
    if [ "X$THEY_DIFFER" != X ]; then
      diff -u "$PR_DAS_QUERY_LOG" "$BASELINE_DAS_QUERY_LOG" || true
      WFS_WITH_DAS_INCONSISTENCY=$WF_NUMBER,$WFS_WITH_DAS_INCONSISTENCY
    fi
  fi 
done

echo $WFS_WITH_DAS_INCONSISTENCY >> $WORKSPACE/$DAS_NON_CONSISTENT_WFS_FILE
echo "COMPARISON${TEST_FLAVOR_STR};RUNNING,Comparison with the ${UC_TEST_FLAVOR} baseline,See results,See results" >> ${RESULTS_FILE}
if [ "$DRY_RUN" = "" ] ; then
  send_jenkins_artifacts ${RESULTS_FILE} ${PR_BASELINE_JOBDIR}/testsResults/comparison${UC_TEST_FLAVOR}.txt
fi

DQM_PID=""
if $DQM_COMPARISON_TEST ; then
  mark_commit_status_all_prs "${GH_COMP_CONTEXT}" 'pending' -u "${BUILD_URL}" -d "Running DQM bin by bin comparison" || true
  (compareDQMOutput.py -b $WORKSPACE/data/$COMPARISON_RELEASE/ -p $WORKSPACE/data/PR-${PR_NUM} -o $CMS_BOT_DIR/dqm-comparison/dqmComparisonOutput/ -l "$PULL_REQUESTS" -t ${BUILD_ID} -r $COMPARISON_RELEASE -s $WORKSPACE/upload/ -j $NUM_PROC > $WORKSPACE/upload/dqmBinByBinLog.log 2>&1 || true) &
  DQM_PID="$!"
fi

echo "DQM_PID: ${DQM_PID}, PID_WAIT: ${PID_WAIT}"
#Run product size comparison script for Phase2 workflow
mkdir compareProducts && pushd compareProducts
  cp $CMS_BOT_DIR/comparisons/compareProducts.* ./
  ./compareProducts.sh $WORKSPACE/data/PR-$PR_NUM/136.874_*/step3.root $WORKSPACE/data/$COMPARISON_RELEASE/136.874_*/step3.root _ 100 10 > products_AOD.log || true
  ./compareProducts.sh $WORKSPACE/data/PR-$PR_NUM/136.874_*/step3_inMINIAOD.root $WORKSPACE/data/$COMPARISON_RELEASE/136.874_*/step3_inMINIAOD.root _ 100 10 > products_MINIAOD.log || true
  mv products_AOD.log $WORKSPACE/upload/products_AOD.log
  mv products_MINIAOD.log $WORKSPACE/upload/products_MINIAOD.log
popd

[ "${PID_WAIT}" = "" ] || wait ${PID_WAIT}
PID_WAIT=""
set +x
# --------------------------------------------------------------------------
# Default Comparison
# --------------------------------------------------------------------------
if [ "X$RUN_DEFAULT_COMP" = Xtrue ]; then
  mark_commit_status_all_prs "${GH_COMP_CONTEXT}" 'pending' -u "${BUILD_URL}" -d "Running default comparison" || true
  echo "Started with default comparison at `date`"
  
  RELMON_COMP_DIR=$WORKSPACE/results/default-comparison
  mkdir $RELMON_COMP_DIR

  if [ "X$RUN_JR_COMP" = Xtrue ]; then
    RELMON_COMP_PARAMS_FILE=$RELMON_COMP_DIR/RelMonComparisonParams.txt
    $CMS_BOT_DIR/comparisons/analyzeFWComparison.py $JR_COMP_DIR $RELMON_COMP_PARAMS_FILE -R >> $RELMON_COMP_DIR/RelMonAssignedParameters.log 2>&1
  fi
  PID_WAIT=""
  for WF in ${WORKFLOWS_TO_COMPARE//,/ }; do 
    WF_FILE=$(basename $WF)
    WF_DIR=`echo $WF | cut -d "/" -f1`
    WF_NUMBER=`echo $WF | cut -d'_' -f1`

    #create the output dir
    OUTPUT_DIR=$WORKSPACE/results/default-comparison/$WF_DIR
    mkdir -p $OUTPUT_DIR

    # If there is a file assigning custom thresholds from the results of the FWlite (JR) comparison, use it
    if [ "X$RUN_JR_COMP" = Xtrue ]; then
      eval $( cat $RELMON_COMP_PARAMS_FILE | grep "FOR_WF=$WF_NUMBER;" )
      echo "TH=$TH"
      if [ "${TH}" = "" ] ; then TH="0.999999999999"; echo "Overriding TH=$TH" ; fi
      TH_PARAM="-t $TH "
    fi

    #requires checking out Utilities/RelMon from the release. It has already been done at the begining of this script. 

    # create a mini script for running this comparisons in parallel
    echo '#!/bin/sh -ex' > $WORKSPACE/results/default-comparison/command-$WF_NUMBER
    echo "ERR=0" >> $WORKSPACE/results/default-comparison/command-$WF_NUMBER
    echo "compare_using_files.py -B DQM/TimerService@3 $WORKSPACE/results/files/$WF_DIR/$COMPARISON_RELEASE-$WF_FILE $WORKSPACE/results/files/$WF_DIR/$PR_NUM-$WF_FILE -o $OUTPUT_DIR --metas \" $COMPARISON_RELEASE @@@ $COMPARISON_RELEASE + $PR_NUM \" --use_black_file -C -R -p --no_successes -s b2b $TH_PARAM --standalone >> ${OUTPUT_DIR}RelMonComp-$WF_NUMBER.log 2>&1 || ERR=1" >> $WORKSPACE/results/default-comparison/command-$WF_NUMBER
    echo "cp $OUTPUT_DIR/RelMonSummary.html $OUTPUT_DIR/index.html || true" >> $WORKSPACE/results/default-comparison/command-$WF_NUMBER
    echo 'exit $ERR' >> $WORKSPACE/results/default-comparison/command-$WF_NUMBER
    chmod 755 $WORKSPACE/results/default-comparison/command-$WF_NUMBER
    wait_dqm_comp 1
    echo "Running $WORKSPACE/results/default-comparison/command-$WF_NUMBER"
    ($WORKSPACE/results/default-comparison/command-$WF_NUMBER > ${OUTPUT_DIR}/cmd.log 2>&1 || touch $WORKSPACE/results/default-comparison/error-$WF_NUMBER) &
    PID_WAIT="$! ${PID_WAIT}"
    echo "PIDS: ${PID_WAIT}"
  done
  echo "Jobs: $(jobs -p | wc -l)"
fi

#-----------------------------------
# Comparisons of edm::TriggerResults
#-----------------------------------
RUN_TR_COMP=true # placeholder: to be configured upstream?
if [ "X$RUN_TR_COMP" = Xtrue ]; then
  echo "[`date`] Starting comparisons of edm::TriggerResults"
  mkdir -p ${WORKSPACE}/upload/triggerResults
  PID_WAIT=""
  for WF in ${WORKFLOWS_TO_COMPARE//,/ }; do
    wait_dqm_comp 1
    WF_DIR=`echo ${WF} | cut -d "/" -f1`
    echo "Running: edm::TriggerResults ${WF_DIR}"
    (${CMS_BOT_DIR}/compareTriggerResults -r ${WORKSPACE}/data/${COMPARISON_RELEASE} -t ${WORKSPACE}/data/PR-${PR_NUM} \
      -f "*/${WF_DIR}/step*.root" -o ${WORKSPACE}/upload/triggerResults > ${WORKSPACE}/upload/triggerResults/${WF_DIR}.log 2>&1 || true) &
    PID_WAIT="$! ${PID_WAIT}"
    echo "PIDS: ${PID_WAIT}"
  done
  echo "Jobs: $(jobs -p | wc -l)"
fi

wait || true
if $DQM_COMPARISON_TEST ; then
  echo "DQM_BIN_BY_BIN_COMPARISON${TEST_FLAVOR_STR};OK,DQM bin by bin ${UC_TEST_FLAVOR} comparison,See results,/SDT/jenkins-artifacts/${COMP_UPLOAD_DIR}/dqm-histo-comparison-summary.html" >> ${RESULTS_FILE}
fi
if [ "X$RUN_DEFAULT_COMP" = Xtrue ]; then
  rm -f $WORKSPACE/results/default-comparison/cmdlog-*
  echo "Finished with default comparison at `date`"
  if [ "X${FILTER_FAILED_COMPARISON}" = "Xtrue" ] ; then
    for f in $WORKSPACE/results/default-comparison/* ; do
      filter_failed_comparison "$f"
    done
  fi
fi
if [ "X$RUN_TR_COMP" = Xtrue ]; then
  echo "[`date`] Done comparisons of edm::TriggerResults"
  ${CMS_BOT_DIR}/compareTriggerResultsSummary -i ${WORKSPACE}/upload/triggerResults -f "*/*.json" -o ${WORKSPACE}/upload/triggerResults/index.html -F html > ${WORKSPACE}/upload/triggerResults.log 2>&1 || true
  echo "[`date`] Summary of TriggerResults comparisons saved in ${WORKSPACE}/upload/triggerResults.log"
  echo "HLT_TRIGGER_COMPARISON${TEST_FLAVOR_STR};OK,HLT Trigger ${UC_TEST_FLAVOR} comparison,See results,/SDT/jenkins-artifacts/${COMP_UPLOAD_DIR}/triggerResults/" >> ${RESULTS_FILE}
fi

# --------------------------------------------------------------------------
# JR-Comparison
# --------------------------------------------------------------------------
#This is used mainly for testing. In jenkins the 3 forms of comparisons are always run. But if you are testing you can control
#which comparison is run.
if [ "X$RUN_JR_COMP" = Xtrue ]; then
  mark_commit_status_all_prs "${GH_COMP_CONTEXT}" 'pending' -u "${BUILD_URL}" -d "Running JR comparion" || true
  pushd $JR_COMP_DIR
    echo "Start JR comparison at `date`"
    echo  "$CMS_BOT_DIR/comparisons/validateJR.sh $WORKSPACE/data/PR-$PR_NUM $WORKSPACE/data/$COMPARISON_RELEASE OldVSNew $CMS_BOT_DIR/comparisons/matrix_RE.txt >> $JR_COMP_DIR/validateJR.log 2>&1" > $JR_COMP_DIR/command
    (LD_LIBRARY_PATH=$WORKSPACE/validateJR_lib:${LD_LIBRARY_PATH} $CMS_BOT_DIR/comparisons/validateJR.sh $WORKSPACE/data/PR-$PR_NUM $WORKSPACE/data/$COMPARISON_RELEASE OldVSNew $CMS_BOT_DIR/comparisons/matrix_RE.txt >> $JR_COMP_DIR/validateJR.log 2>&1) || true
    echo "Finished with JR comparison at `date`:"
  popd
  rm -rf $WORKSPACE/validateJR_lib
  (${CMSBOT_PYTHON_CMD} $CMS_BOT_DIR/logRootQA.py $WORKSPACE/data/${COMPARISON_RELEASE} $WORKSPACE/data/PR-${PR_NUM} ${JR_COMP_DIR} $WORKSPACE/results/default-comparison JR || true) >${JR_COMP_DIR}/logRootQA-JR.log 2>&1 &
fi

# ----------------------------------------------------------------------------
# Alternative Comparison
# ----------------------------------------------------------------------------

if [ "X$RUN_ALT_COMP" = Xtrue ]; then
  mark_commit_status_all_prs "${GH_COMP_CONTEXT}" 'pending' -u "${BUILD_URL}" -d "Running alternative comparison" || true
  echo "Started with alternative comparison at `date`"
  
  ALT_COMP_DIR=$WORKSPACE/results/alternative-comparison
  mkdir -p $ALT_COMP_DIR
  DQM_COMP_PARAMS_FILE=$ALT_COMP_DIR/comparisonParams.txt

  if [ "X$RUN_JR_COMP" = Xtrue ]; then
    $CMS_BOT_DIR/comparisons/analyzeFWComparison.py $JR_COMP_DIR $DQM_COMP_PARAMS_FILE >> $ALT_COMP_DIR/assignedParameters.log 2>&1
  fi
  for WF in ${WORKFLOWS_TO_COMPARE//,/ }; do 

    WF_FILE=$(basename $WF)
    WF_DIR=`echo $WF | cut -d "/" -f1`
    WF_NUMBER=`echo $WF | cut -d'_' -f1`
    BASE_FILE=$WORKSPACE/results/files/$WF_DIR/$COMPARISON_RELEASE-$WF_FILE
    COMP_FILE=$WORKSPACE/results/files/$WF_DIR/$PR_NUM-$WF_FILE
  
    mkdir -p $ALT_COMP_DIR/$WF_NUMBER
    eval $( cat $DQM_COMP_PARAMS_FILE | grep "FOR_WF=$WF_NUMBER;" )
    if [ "${MOD}" = "" ] ; then MOD=0; echo "Overriding MOD=$MOD";  fi
    echo "MOD=$MOD"

    # create a mini script for running this comparisons in parallel
    echo '#!/bin/sh -ex' > $ALT_COMP_DIR/command-$WF_NUMBER
    echo "ERR=0" >> $ALT_COMP_DIR/command-$WF_NUMBER
    echo "cd $ALT_COMP_DIR/$WF_NUMBER" >> $ALT_COMP_DIR/command-$WF_NUMBER
    echo "$CMS_BOT_DIR/comparisons/makeDiff.sh $BASE_FILE $COMP_FILE $WF_NUMBER-result.ps 0 $MOD || ERR=1" >> $ALT_COMP_DIR/command-$WF_NUMBER
    echo "mv diff.ps $ALT_COMP_DIR/$WF_NUMBER-result.ps || true" >> $ALT_COMP_DIR/command-$WF_NUMBER
    echo "mv diff.pdf $ALT_COMP_DIR/$WF_NUMBER-result.pdf || true" >> $ALT_COMP_DIR/command-$WF_NUMBER
    echo "gzip -f $ALT_COMP_DIR/$WF_NUMBER-result.ps || true" >> $ALT_COMP_DIR/command-$WF_NUMBER
    echo "gzip -f $ALT_COMP_DIR/$WF_NUMBER-result.pdf || true" >> $ALT_COMP_DIR/command-$WF_NUMBER
    echo 'exit $ERR' >> $ALT_COMP_DIR/command-$WF_NUMBER

    chmod 755 $ALT_COMP_DIR/command-$WF_NUMBER
    while [ $(jobs -p | wc -l) -ge ${NUM_PROC} ] ; do sleep 0.1 ; done
    echo "Running $ALT_COMP_DIR/command-$WF_NUMBER"
    (LD_LIBRARY_PATH=$WORKSPACE/validateALT_lib:${LD_LIBRARY_PATH} $ALT_COMP_DIR/command-$WF_NUMBER > $ALT_COMP_DIR/runDQMComp-$WF_NUMBER.log 2>&1 || touch $ALT_COMP_DIR/error-$WF_NUMBER) &
  done
  echo "Jobs: $(jobs -p | wc -l)"
  wait
  rm -rf $WORKSPACE/validateALT_lib
  echo "Finished with alternative comparison at `date`"
fi
wait || true
#----------------------------------
# Comparison summary
#----------------------------------
if [ "X$RUN_JR_COMP" = Xtrue ]; then
  if [ "X$RUN_DEFAULT_COMP" = Xtrue ]; then
    QALOG=$JR_COMP_DIR/logRootQA.log
    JRHTML=$WORKSPACE/upload/validateJR.html
    mark_commit_status_all_prs "${GH_COMP_CONTEXT}" 'pending' -u "${BUILD_URL}" -d "Generating comparison summary" || true
    echo 'Doing histogram, log and root comparison:'
    (${CMSBOT_PYTHON_CMD} $CMS_BOT_DIR/logRootQA.py $WORKSPACE/data/${COMPARISON_RELEASE} $WORKSPACE/data/PR-${PR_NUM} ${JR_COMP_DIR} $WORKSPACE/results/default-comparison  >> $QALOG 2>&1) || true
    (grep -a SUMMARY $QALOG | cut -d' ' -f2-100 >> $JR_COMP_DIR/qaResultsSummary.log 2>&1) || true
    echo "<html><body><h3>Default comparison: Workflows with failed comparisons</h3>" > $JRHTML
    echo "<table><tr><td>WF #</td><td>Failed</td></tr>" >> $JRHTML
    grep -a 'Histogram comparison details' $QALOG  | grep '\.log *\[[1-9][0-9]* *, *[1-9][0-9]*'  | sed 's|.*/default-comparison/\(\([^_]*\)_.*\)RelMonComp.*.log \[[1-9][0-9]* *, *\([1-9][0-9]*\) *,.*|<tr><td><a href="\1">\2</a></td><td align="right">\3</td></tr>|' >> $JRHTML
    if [ $(cat $JRHTML | wc -l) -eq 2 ] ; then
      echo "<tr><td>ALL OK</td><td>No errors</td></tr></table>" >> $JRHTML
    else
      echo "</table>" >> $JRHTML
    fi
    echo "<h3>Default comparison: Workflows with reco comparison differences</h3>" >> $JRHTML
    echo "<table><tr><td>WF #</td><td>Differences</td></tr>" >> $JRHTML
    grep -a 'JR results differ' $JR_COMP_DIR/logRootQA-JR.log | awk '{ split($0,a," "); print "<tr><td><a href=\"validateJR/"a[5]"\">"a[5]"</a></td><td align=\"right\">"a[4]"</td></tr>" }' >> $JRHTML
    if [ $(tail -1 $JRHTML | grep "Differences" | wc -l) -eq 1 ] ; then
      echo "<tr><td>ALL OK</td><td>No differences</td></tr></table>" >> $JRHTML
    else
      echo "</table>" >> $JRHTML
    fi
    echo "<h3>Default comparison: Workflows with reco comparison failures</h3>" >> $JRHTML
    echo "<table><tr><td>WF #</td><td>Failures log</td></tr>" >> $JRHTML
    grep -a 'JR results failed' $JR_COMP_DIR/logRootQA-JR.log | awk '{ split($0,a," "); print "<tr><td><a href=\"validateJR/"a[4]"\">"a[4]"</a></td><td align=\"right\"><a href=\"validateJR/"a[4]"/"a[4]".log\">log</a></td></tr>" }' >> $JRHTML
    if [ $(tail -1 $JRHTML | grep "Failures" | wc -l) -eq 1 ] ; then
      echo "<tr><td>ALL OK</td><td>No failures</td></tr></table>" >> $JRHTML
    else
      echo "</table>" >> $JRHTML
    fi
    echo "</body></html>" >> $JRHTML
    echo "FAILED_COMPARISON${TEST_FLAVOR_STR};OK,Comparison ${UC_TEST_FLAVOR} failed,See failed,/SDT/jenkins-artifacts/${COMP_UPLOAD_DIR}/validateJR.html" >> ${RESULTS_FILE}
  fi
fi

if [ "X$RUN_TR_COMP" = Xtrue ]; then
  if [ -f ${JR_COMP_DIR}/qaResultsSummary.log ]; then
    grep -a SUMMARY ${WORKSPACE}/upload/triggerResults.log | cut -d' ' -f2-100 >> ${JR_COMP_DIR}/qaResultsSummary.log 2>&1 || true
    sed -i "s|TriggerResults|[TriggerResults](${JENKINS_ARTIFACTS_URL}/${COMP_UPLOAD_DIR}/triggerResults)|g" ${JR_COMP_DIR}/qaResultsSummary.log
    echo "[`date`] One-line Summary of TriggerResults comparisons appended to ${JR_COMP_DIR}/qaResultsSummary.log"
  fi
fi

set -x
wait || true

cd $WORKSPACE
mkdir -p upload/alternative-comparisons

#default-comparison
for f in results/default-comparison/* ; do
  if [ -e $f/.deleteme ] ; then
    rm -rf $f
    echo "Deleting $f"
  elif [ -e $f ] ; then
    mv $f upload/
  fi
done

#alternative-comparison
alt_dir=results/alternative-comparison
for f in $(find ${alt_dir} -maxdepth 1 -name 'command*' -o -name '*.ps' -o -name '*.gz' -o -name '*.log' -o -name '*.txt') ; do
  mv $f upload/alternative-comparisons/
done

#JR-comparison
for x in $(find results/JR-comparison -maxdepth 2 -name 'command*' -o -name '*.log' -o -name '*.png' -type f) ; do
  f=$(echo $x | sed 's|results/JR-comparison/||')
  d=$(dirname upload/validateJR/$f)
  [ -d $d ] || mkdir -p $d
  mv results/JR-comparison/$f $d/
done

#files
if [ -e results/files ] ; then
  mkdir -p upload/files
  for file in $(find results/files -mindepth 2 -maxdepth 2 -name '*' | sed 's|^results/files/||') ; do
    fname=$(basename $file)
    wfdir=$(dirname $file)
    mkdir -p upload/files/${wfdir}
    case $file in 
      */${COMPARISON_RELEASE}-*) SRC_FILE=../../../../../${BASELINE_DIR}/${wfdir}/$(echo $fname | sed "s|${COMPARISON_RELEASE}-||") ;;
      *)                     SRC_FILE=../../../../../${PR_BASELINE_DIR}/${wfdir}/$(echo $fname | sed "s|$PR_NUM-||") ;;
    esac
    ln -sf $SRC_FILE upload/files/$file
  done
fi

mkdir -p $WORKSPACE/testsResults
sed -i "s/^COMPARISON${TEST_FLAVOR_STR};RUNNING,/COMPARISON${TEST_FLAVOR_STR};$BUILD_NUMBER,/g" ${RESULTS_FILE}
mv ${RESULTS_FILE} $WORKSPACE/testsResults/

[ -e comparisonDetails.txt ] && mv comparisonDetails.txt upload/
${CMS_BOT_DIR}/report-pull-request-results "COMPARISON_READY" --report-url ${PR_RESULT_URL} \
  -f $WORKSPACE/wf_errors.txt --f2 $WORKSPACE/wf_non_consistent_das.txt \
  --missing_map $WORKSPACE/results/JR-comparison/missing_map.txt  --report-file $WORKSPACE/testsResults/20-comparison-report.res

if [ "${TEST_FLAVOR}" != "" ] ; then
  sed -i -e "s|## Comparison Summary|## ${UC_TEST_FLAVOR} Comparison Summary|" $WORKSPACE/testsResults/20-comparison-report.res
  mv $WORKSPACE/testsResults/20-comparison-report.res $WORKSPACE/testsResults/20-${TEST_FLAVOR}-comparison-report.res
fi

if [ "$DRY_RUN" = "" ] ; then
  send_jenkins_artifacts $WORKSPACE/upload/ ${COMP_UPLOAD_DIR}/
  send_jenkins_artifacts $WORKSPACE/testsResults/ ${PR_BASELINE_JOBDIR}/testsResults/
fi
mark_commit_status_all_prs "${GH_COMP_CONTEXT}" 'success' -u "${BUILD_URL}" -d "Finished, please check results" || true
echo "All done at `date`"
