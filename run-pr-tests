#!/bin/sh -ex

CMSBUILD_KEY="/build/cmsbuild/cmsbuild.keytab"
case $NODE_NAME in
  lxplus* ) CMSBUILD_KEY="$CMSBUILD_KEYTAB/cmsbuild.keytab" ;;
esac

function Jenkins_GetCPU ()
{
  ACTUAL_CPU=$(getconf _NPROCESSORS_ONLN)
  case $NODE_NAME in
    lxplus* ) ACTUAL_CPU=$(echo $ACTUAL_CPU / 2 | bc) ;;
  esac
  if [ "X$1" != "X" ] ; then
    ACTUAL_CPU=$(echo "$ACTUAL_CPU*$1" | bc)
  fi
  echo $ACTUAL_CPU
}

# In case we have kerberos and aklog reset token every time you run.
if [ ! X`which aklog` = X ]; then
  aklog
fi
if [ ! X`which kinit` = X ]; then
  kinit cmsbuild@CERN.CH -k -t $CMSBUILD_KEY || true
fi

$WORKSPACE/cms-bot/modify_comment.py -r cms-sw/cmssw -t JENKINS_TEST_URL -m "https://cmssdt.cern.ch/jenkins/job/ib-any-integration/${BUILD_NUMBER}/console" $PULL_REQUEST || true
# to not modify the behavior of other scripts that use the AUTO_POST_MESSAGE parameter
if [ "X$AUTO_POST_MESSAGE" != Xtrue ]; then
  DRY_RUN='--no-post'
fi

cd "$WORKSPACE"

### this is for triggering the comparison with the baseline
  PULL_REQUEST_NUMBER=$PULL_REQUEST
  PULL_REQUEST_JOB_ID=${BUILD_NUMBER}
### to know at the end of the tests if everything went ok
ALL_OK=true
BUILD_OK=true
UNIT_TESTS_OK=true
RELVALS_OK=true
ADDON_OK=true
REAL_ARCH=-`cat /proc/cpuinfo | grep vendor_id | head -n 1 | sed "s/.*: //"`
git config --global user.name "Cms Build"
git config --global user.github cmsbuild
git config --global user.email cmsbuild@cern.ch
export SCRAM_ARCH=$ARCHITECTURE

if [[ $RELEASE_FORMAT != *-* ]]; then
  RELEASE_QUEUE=$RELEASE_FORMAT
  for SCRAM_REL in $(scram l -c $RELEASE_FORMAT | grep -v -f $WORKSPACE/cms-bot/ignore-releases-for-tests | awk '{print $2}' | sort -r) ;  do
    FILE_CHECK="/data/sdt/SDT/jenkins-artifacts/ib-baseline-tests/$SCRAM_REL/$SCRAM_ARCH/$REAL_ARCH/matrix-results/wf_errors.txt"
    if ssh cmsbuild@cmssdt01.cern.ch test -f $FILE_CHECK ; then
      RELEASE_FORMAT=$SCRAM_REL
      break
    fi
  done
else
  RELEASE_QUEUE=`$WORKSPACE/cms-bot/get-pr-branch $PULL_REQUEST`
fi

# creation of results summary file
cp $WORKSPACE/cms-bot/templates/PullRequestSummary.html $WORKSPACE/summary.html
cp $WORKSPACE/cms-bot/templates/js/renderPRTests.js $WORKSPACE/renderPRTests.js
RESULTS_FILE=$WORKSPACE/testsResults.txt
touch $RESULTS_FILE
echo 'PR_NUMBER;'$PULL_REQUEST >> $RESULTS_FILE
echo 'ADDITIONAL_PRS;'$ADDITIONAL_PULL_REQUESTS >> $RESULTS_FILE
echo 'BASE_IB;'$RELEASE_FORMAT >> $RESULTS_FILE
echo 'BUILD_NUMBER;'$BUILD_NUMBER >> $RESULTS_FILE

case $RELEASE_FORMAT in
  *SLHC*)
     DO_ADDON_TESTS=false
  ;;
esac
scram project $RELEASE_FORMAT
cd $RELEASE_FORMAT
eval `scram run -sh`
cd src
git config --global --replace-all merge.renamelimit 2500

# Requests is used to mark the commits
# We should really make this part of the system requirements.
pushd $WORKSPACE/cms-bot
  wget --no-check-certificate https://pypi.python.org/packages/source/r/requests/requests-2.3.0.tar.gz#md5=7449ffdc8ec9ac37bbcd286003c80f00
  tar -xvf requests-2.3.0.tar.gz
  mv requests-2.3.0/requests/ requests
popd

GIT_MERGE_RESULT_FILE=$WORKSPACE/git-merge-result
# use the branch name if necesary
if [ "X$BRANCH_NAME" = X ]; then
  (git cms-merge-topic -u $PULL_REQUEST && echo 'ALL_OK') 2>&1 | tee -a $GIT_MERGE_RESULT_FILE
else
  (git cms-merge-topic -u $BRANCH_NAME && echo 'ALL_OK') 2>&1 | tee -a $GIT_MERGE_RESULT_FILE
fi

# this is to test several pull requests at the same time
for PR in ${ADDITIONAL_PULL_REQUESTS//,/ }; do
  echo 'I will add the following pull request to the test'
  echo $PR;
  git cms-merge-topic -u $PR 2>&1 | tee -a $GIT_MERGE_RESULT_FILE
done

if grep 'Automatic merge failed' $GIT_MERGE_RESULT_FILE; then
  $WORKSPACE/cms-bot/report-pull-request-results NOT_MERGEABLE  --pr $PULL_REQUEST_NUMBER --pr-job-id ${BUILD_NUMBER} $DRY_RUN
  exit 0   
fi

if grep "Couldn't find remote ref" $GIT_MERGE_RESULT_FILE; then
  echo "Please add the branch name to the parameters"
  $WORKSPACE/cms-bot/report-pull-request-results REMOTE_REF_ISSUE --pr $PULL_REQUEST_NUMBER --pr-job-id ${BUILD_NUMBER} $DRY_RUN
  exit 1
fi

# look for any other error in general
if ! grep "ALL_OK" $GIT_MERGE_RESULT_FILE; then
  echo "There was an error while running git cms-merge-topic"
  $WORKSPACE/cms-bot/report-pull-request-results GIT_CMS_MERGE_TOPIC_ISSUE --pr $PULL_REQUEST_NUMBER --pr-job-id ${BUILD_NUMBER} $DRY_RUN
  exit 0
fi

#############################################
# Check if there are unwanted commits that came with the merge. 
############################################
RECENT_COMMITS_FILE=$WORKSPACE/git-recent-commits
RECENT_COMMITS_LOG_FILE=$WORKSPACE/git-log-recent-commits
IB_DATE=`echo $RELEASE_FORMAT | sed -e 's/^.*_//g'`
YEAR_MONTH_DAY=`echo $IB_DATE | sed -e 's/-[0-9]*$//g'`
HOUR=`echo $IB_DATE | sed -e "s/$YEAR_MONTH_DAY-//g" | sed -e 's/0*//g'`
git rev-list --after="$YEAR_MONTH_DAY $HOUR:00" HEAD --merges 2>&1 | tee -a $RECENT_COMMITS_FILE
git log --after="$YEAR_MONTH_DAY $HOUR:00" HEAD --merges 2>&1 | tee -a $RECENT_COMMITS_LOG_FILE

#If Fireworks is the only package involved I only compile and run unit tests
ONLY_FIREWORKS=false
if [ "X$APPLY_FIREWORKS_RULE" = Xtrue ]; then
  ls $WORKSPACE/$RELEASE_FORMAT/src
  NUM_DIRS=$((`(find $WORKSPACE/$RELEASE_FORMAT/src -maxdepth 1 -type d -print | grep -v '.git' | grep -v 'FWCore' | wc -l)`-1))
  if [ "$NUM_DIRS" == 1 ]; then
    if ls | grep 'Fireworks'; then
      ONLY_FIREWORKS=true
      echo 'This pr only involves Fireworks!' 
      echo 'Only compiling and running unit tests'
    fi 
  fi
fi

#get the latest commit and mark it as pending
pushd $WORKSPACE/$RELEASE_FORMAT/src
  if [ "X$BRANCH_NAME" = X ]; then
    LAST_COMMIT=`git log cms-sw/refs/pull/$PULL_REQUEST/head --pretty="%H" | head -n1` 
  else
    LAST_COMMIT=`git log ${BRANCH_NAME//:/\/} --pretty="%H" | head -n1`
  fi
popd

$WORKSPACE/cms-bot/report-pull-request-results TESTS_RUNNING --pr $PULL_REQUEST_NUMBER -c $LAST_COMMIT --pr-job-id ${BUILD_NUMBER} $DRY_RUN

cp -r $WORKSPACE/$RELEASE_FORMAT/src $WORKSPACE/$RELEASE_FORMAT/src.orig
git log --oneline --merges ${CMSSW_VERSION}..
$WORKSPACE/cms-bot/report-pull-request-results TESTS_RUNNING --pr $PULL_REQUEST_NUMBER -c $LAST_COMMIT --pr-job-id ${BUILD_NUMBER} --add-message "Compiling" $DRY_RUN

# #############################################
# test compilation with Clang
# ############################################
echo 'test clang compilation'

CONFIG_MAP_URL="https://raw.githubusercontent.com/cms-sw/cms-bot/master/config.map"

NEED_CLANG_TEST=false
if curl $CONFIG_MAP_URL | grep $RELEASE_QUEUE | grep PRS_TEST_CLANG= | grep SCRAM_ARCH=$ARCHITECTURE; then
  NEED_CLANG_TEST=true
fi

if [ "X$TEST_CLANG_COMPILATION" = Xtrue -a $NEED_CLANG_TEST = true ]; then
  $WORKSPACE/cms-bot/report-pull-request-results TESTS_RUNNING --pr $PULL_REQUEST_NUMBER -c $LAST_COMMIT --pr-job-id ${BUILD_NUMBER} --add-message "Testing Clang compilation" $DRY_RUN

  #first, add the command to the log
  CLANG_CMD="scram b vclean && scram build -k -j $(Jenkins_GetCPU 2) USER_CXXFLAGS='-fsyntax-only' COMPILER='llvm compile'"
  echo $CLANG_CMD > $WORKSPACE/buildClang.log

  (eval $CLANG_CMD && echo 'ALL_OK') 2>&1 | tee -a $WORKSPACE/buildClang.log

  TEST_ERRORS=`grep -E "^gmake: .* Error [0-9]" $WORKSPACE/buildClang.log` || true
  GENERAL_ERRORS=`grep "ALL_OK" $WORKSPACE/buildClang.log` || true

  if [ "X$TEST_ERRORS" != "X" -o "X$GENERAL_ERRORS" = "X" ]; then
    echo "Errors when testing compilation with clang"
    echo 'CLANG_COMPILATION_RESULTS;ERROR' >> $RESULTS_FILE
    ALL_OK=false
    CLANG_BUILD_OK=false
  else
    echo "the clan compilation had no errors!!"
    echo 'CLANG_COMPILATION_RESULTS;OK' >> $RESULTS_FILE
  fi
else
  echo 'CLANG_COMPILATION_RESULTS;NOTRUN' >> $RESULTS_FILE
fi

#
# Static checks
#
if [ "X$DO_STATIC_CHECKS" = Xtrue -a "$ONLY_FIREWORKS" = false ]; then
  $WORKSPACE/cms-bot/report-pull-request-results TESTS_RUNNING --pr $PULL_REQUEST_NUMBER -c $LAST_COMMIT --pr-job-id ${BUILD_NUMBER} --add-message "Running Static Checks" $DRY_RUN
  echo 'STATIC_CHECKS;OK' >> $RESULTS_FILE
  echo '--------------------------------------'
  pushd $WORKSPACE/$RELEASE_FORMAT
  git cms-addpkg Utilities/StaticAnalyzers
  mkdir $WORKSPACE/llvm-analysis
  SCRAM_IGNORE_PACKAGES="Fireworks/% Utilities/StaticAnalyzers" USER_LLVM_CHECKERS="-enable-checker threadsafety -enable-checker cms -disable-checker cms.FunctionDumper" scram b -k -j $(Jenkins_GetCPU 2) checker SCRAM_IGNORE_SUBDIRS=test 2>&1 | tee -a $WORKSPACE/llvm-analysis/runStaticChecks.log
  cp -R $WORKSPACE/$RELEASE_FORMAT/llvm-analysis/*/* $WORKSPACE/llvm-analysis || true
  echo 'END OF STATIC CHECKS'
  echo '--------------------------------------'
  popd
else
  echo 'STATIC_CHECKS;NOTRUN' >> $RESULTS_FILE
fi

pushd $WORKSPACE/$RELEASE_FORMAT
  rm -rf src
  mv src.orig src
popd
scram build clean
git cms-checkdeps -A -a

############################################
# Force the run of DQM tests if necessary
############################################
if ls $WORKSPACE/$RELEASE_FORMAT/src/| grep -i -E "dqm.*|HLTriggerOffline|Validation"; then
  echo "I will make sure that DQM tests will be run"
  if ls $WORKSPACE/$RELEASE_FORMAT/src/| grep "DQMServices"; then
    echo DQMServices is already there
      if ls $WORKSPACE/$RELEASE_FORMAT/src/DQMServices/| grep "Components"; then
        echo "and DQMServices/Components is there"
      else
        git cms-addpkg DQMServices/Components
      fi
  else
    echo "checking out DQMServices"
    git cms-addpkg DQMServices
  fi
fi

# #############################################
# test compilation with GCC
# ############################################
COMPILATION_CMD="scram b vclean && scram b -k -j $(Jenkins_GetCPU 2)"
echo $COMPILATION_CMD > $WORKSPACE/build.log
(eval $COMPILATION_CMD && echo 'ALL_OK') 2>&1 | tee -a $WORKSPACE/build.log
echo 'END OF BUILD LOG'
echo '--------------------------------------'

TEST_ERRORS=`grep -E "^gmake: .* Error [0-9]" $WORKSPACE/build.log` || true
GENERAL_ERRORS=`grep "ALL_OK" $WORKSPACE/build.log` || true

if [ "X$TEST_ERRORS" != "X" -o "X$GENERAL_ERRORS" = "X" ]; then
    echo "Errors when building"
    echo 'COMPILATION_RESULTS;ERROR' >> $RESULTS_FILE
    ALL_OK=false
    BUILD_OK=false
else  
    echo "the build had no errors!!"
    echo 'COMPILATION_RESULTS;OK' >> $RESULTS_FILE
fi

#
# Unit tests
#
if [ "X$DO_TESTS" = Xtrue -a "X$BUILD_OK" = Xtrue ]; then
  $WORKSPACE/cms-bot/report-pull-request-results TESTS_RUNNING --pr $PULL_REQUEST_NUMBER -c $LAST_COMMIT --pr-job-id ${BUILD_NUMBER} --add-message "Running Unit Tests" $DRY_RUN
  echo '--------------------------------------'
  UTESTS_CMD="timeout 7200 scram b -k -j $(Jenkins_GetCPU)  runtests "
  echo $UTESTS_CMD > $WORKSPACE/unitTests.log
  (eval $UTESTS_CMD && echo 'ALL_OK') 2>&1 | tee -a $WORKSPACE/unitTests.log
  echo 'END OF UNIT TESTS'
  echo '--------------------------------------'
  #######################################
  # check if DQM Tests where run
  #######################################
  if ls $WORKSPACE/$RELEASE_FORMAT/src/DQMServices/Components/test/ | grep -v -E "[a-z]+"; then 
    echo "DQM Tests were run!"
    pushd $WORKSPACE/$RELEASE_FORMAT/src/DQMServices/Components/test/
    ls | grep -v -E "[a-z]+" | xargs -I ARG mv ARG DQMTestsResults
    mkdir $WORKSPACE/DQMTestsResults
    cp -r DQMTestsResults $WORKSPACE/DQMTestsResults
    ls $WORKSPACE
    popd

    echo 'DQM_TESTS;OK' >> $RESULTS_FILE
  else

    echo 'DQM_TESTS;NOTRUN' >> $RESULTS_FILE

  fi

  TEST_ERRORS=`grep -i "had errors" $WORKSPACE/unitTests.log` || true
  GENERAL_ERRORS=`grep "ALL_OK" $WORKSPACE/unitTests.log` || true

  if [ "X$TEST_ERRORS" != "X" -o "X$GENERAL_ERRORS" = "X" ]; then
    echo "Errors in the unit tests"
    echo 'UNIT_TEST_RESULTS;ERROR' >> $RESULTS_FILE
    ALL_OK=false
    UNIT_TESTS_OK=false
  else
    echo 'UNIT_TEST_RESULTS;OK' >> $RESULTS_FILE
  fi


else

  echo 'UNIT_TEST_RESULTS;NOTRUN' >> $RESULTS_FILE
  echo 'DQM_TESTS;NOTRUN' >> $RESULTS_FILE

fi

#
# Matrix tests
#

JOB_REPORTS=""
if [[ $RELEASE_FORMAT != CMSSW_5_3_X* ]] && [ "X$USE_JOB_REPORTS" = Xtrue ]; then
  JOB_REPORTS='--job-reports'
fi

if [ ! "X$MATRIX_EXTRAS" = X ]; then
  MATRIX_EXTRAS="-l `echo $MATRIX_EXTRAS | sed -e 's/[^0-9., ]*//g'`"
fi


if [ "X$DO_SHORT_MATRIX" = Xtrue -a "X$BUILD_OK" = Xtrue -a "$ONLY_FIREWORKS" = false ]; then
    $WORKSPACE/cms-bot/report-pull-request-results TESTS_RUNNING --pr $PULL_REQUEST_NUMBER -c $LAST_COMMIT --pr-job-id ${BUILD_NUMBER} --add-message "Running RelVals" $DRY_RUN
  echo '--------------------------------------'
  mkdir "$WORKSPACE/runTheMatrix-results"
  pushd "$WORKSPACE/runTheMatrix-results"
    
    case $RELEASE_FORMAT in
        *THREADED*)
        THREADED_PARAM='-t 4 --command \"--customise FWCore/Concurrency/dropNonMTSafe.dropNonMTSafe\"'
        ;;
       *)
    esac

    case $RELEASE_FORMAT in
        *SLHCDEV*)
         SLHC_PARAM='-w upgrade'
         WF_LIST="-l 10000,10061,10200,10261,10800,10861,12200,12261,14400,14461,12600,12661,14000,14061,12800,12861,13000,13061,13600,13661,13800,13861"
         ;;
        *SLHC*)
         SLHC_PARAM='-w upgrade'
         WF_LIST="-l 10000,10061,10200,10261,12200,12261,14400,14461,12600,12661,14000,14061,12800,12861,13000,13061,13600,13661,13800,13861"
         ;;
        *)
         WF_LIST="-s $MATRIX_EXTRAS"
        ;;
    esac

    # MATRIX_TIMEOUT is set by jenkins
    dateBefore=$(date +"%s")

    # The --das-options are not correctly interpreted when set as a variable
    EXTRA_RELVALS_OPTION=""
    if [[ $RELEASE_FORMAT != CMSSW_5_3_X* ]] && [ "X$USE_DAS_CACHE" = Xtrue ]; then
      wget --no-check-certificate https://raw.githubusercontent.com/cms-sw/cmsdist/HEAD/das-cache.file
      EXTRA_RELVALS_OPTION='--das-options="--cache das-cache.file --limit 0"'
    fi
    RELVALS_CMD="timeout $MATRIX_TIMEOUT runTheMatrix.py $EXTRA_MATRIX_ARGS $THREADED_PARAM $EXTRA_RELVALS_OPTION $SLHC_PARAM $JOB_REPORTS -j $(Jenkins_GetCPU) $WF_LIST"
    echo $RELVALS_CMD > $WORKSPACE/matrixTests.log
    (eval $RELVALS_CMD && echo 'ALL_OK') 2>&1 | tee -a $WORKSPACE/matrixTests.log

    dateAfter=$(date +"%s")
    diff=$(($dateAfter-$dateBefore))
    
    if [ "$diff" -ge $MATRIX_TIMEOUT ]; then
      echo "------------"  >> $WORKSPACE/matrixTests.log
      echo 'ERROR TIMEOUT' >> $WORKSPACE/matrixTests.log
    fi

  popd
 
  TEST_ERRORS=`grep -i -E "ERROR .*" $WORKSPACE/matrixTests.log` || true
  GENERAL_ERRORS=`grep "ALL_OK" $WORKSPACE/matrixTests.log` || true
     
  if [ "X$TEST_ERRORS" != "X" -o "X$GENERAL_ERRORS" = "X" ]; then
    echo "Errors in the RelVals"

    echo 'MATRIX_TESTS;ERROR' >> $RESULTS_FILE
    echo 'COMPARISON;NOTRUN' >> $RESULTS_FILE

    ALL_OK=false
    RELVALS_OK=false
  else  
    echo "no errors in the RelVals!!"
    echo 'MATRIX_TESTS;OK' >> $RESULTS_FILE
    echo 'COMPARISON;QUEUED' >> $RESULTS_FILE

    TRIGGER_COMPARISON_FILE=$WORKSPACE/'comparison.properties'
    echo "Creating properties file $TRIGGER_COMPARISON_FILE"
    echo "RELEASE_FORMAT=$RELEASE_FORMAT" > $TRIGGER_COMPARISON_FILE
    echo "ARCHITECTURE=${ARCHITECTURE}" >> $TRIGGER_COMPARISON_FILE
    echo "PULL_REQUEST_NUMBER=$PULL_REQUEST_NUMBER" >> $TRIGGER_COMPARISON_FILE
    echo "PULL_REQUEST_JOB_ID=${BUILD_NUMBER}" >> $TRIGGER_COMPARISON_FILE
    echo "REAL_ARCH=$REAL_ARCH" >> $TRIGGER_COMPARISON_FILE
 
   #####################################################################
   #### Run igprof
   #####################################################################
   # for now this is only run for 25202
   
  
  if [ "X$RUN_IGPROF" = Xtrue ]; then
    echo 'IGPROF;QUEQUED' >> $RESULTS_FILE

    TRIGGER_IGPROF_FILE=$WORKSPACE/'igprof.properties'
    echo "Creating properties file $TRIGGER_IGPROF_FILE"   
    echo "RELEASE_FORMAT=$RELEASE_FORMAT" > $TRIGGER_IGPROF_FILE
    echo "ARCHITECTURE=${ARCHITECTURE}" >> $TRIGGER_IGPROF_FILE
    echo "PULL_REQUEST_NUMBER=$PULL_REQUEST_NUMBER" >> $TRIGGER_IGPROF_FILE
    echo "PULL_REQUEST_JOB_ID=${BUILD_NUMBER}" >> $TRIGGER_IGPROF_FILE
    echo "LAST_COMMIT=${LAST_COMMIT}" >> $TRIGGER_IGPROF_FILE
    echo "AUTO_POST_MESSAGE=${AUTO_POST_MESSAGE}" >> $TRIGGER_IGPROF_FILE

  else  
    echo 'IGPROF;NOTRUN' >> $RESULTS_FILE
  fi

  #####################################################################
  #### Run cfg-viewer
  #####################################################################

    if [ "X$RUN_CONFIG_VIEWER" = Xtrue ]; then

      mkdir -p "$WORKSPACE/cfg-viewerResults"
      pushd "$WORKSPACE/cfg-viewerResults"
      cfg-viewer.py -r -s "$WORKSPACE/runTheMatrix-results"
      popd
       sed -i "s/<!--CONFIG_FILES_BROWSER//g" $WORKSPACE/summary.html
       sed -i "s/CONFIG_FILES_BROWSER-->//g" $WORKSPACE/summary.html
       sed -i "s/PARAM_CONFIG_BROWSER/https:\/\/cmssdt.cern.ch\/SDT\/jenkins-artifacts\/pull-request-integration\/PR-${PULL_REQUEST}\/${BUILD_NUMBER}\/cfg-viewerResults\//g" $WORKSPACE/summary.html
    fi
  fi
  
else

  echo 'MATRIX_TESTS;NOTRUN' >> $RESULTS_FILE
  echo 'COMPARISON;NOTRUN' >> $RESULTS_FILE
  echo 'IGPROF;NOTRUN' >> $RESULTS_FILE

fi

#
# AddOn Tetss
#
if [ "X$DO_ADDON_TESTS" = Xtrue -a "X$BUILD_OK" = Xtrue ]; then
  $WORKSPACE/cms-bot/report-pull-request-results TESTS_RUNNING --pr $PULL_REQUEST_NUMBER -c $LAST_COMMIT --pr-job-id ${BUILD_NUMBER} --add-message "Running AddOn Tests" $DRY_RUN
  echo '--------------------------------------'
  ADDON_CMD="addOnTests.py -j $(Jenkins_GetCPU) "
  echo $ADDON_CMD > $WORKSPACE/addOnTests.log
  (eval $ADDON_CMD && echo 'ALL_OK') 2>&1 | tee -a $WORKSPACE/addOnTests.log
  echo 'END OF ADDON TESTS'
  echo '--------------------------------------'
  if [ -d addOnTests ] ; then
    mv addOnTests $WORKSPACE/addOnTests
  fi
  TEST_ERRORS=`grep -i -E ": FAILED .*" $WORKSPACE/addOnTests.log` || true
  GENERAL_ERRORS=`grep "ALL_OK" $WORKSPACE/addOnTests.log` || true

  if [ "X$TEST_ERRORS" != "X" -o "X$GENERAL_ERRORS" = "X" ]; then
    echo "Errors in the addOnTests"
    echo 'ADDON_TESTS;ERROR' >> $RESULTS_FILE
    ALL_OK=false
    ADDON_OK=false
  else
    echo "no errors in the addOnTests!!"
    echo 'ADDON_TESTS;OK' >> $RESULTS_FILE
  fi
else
  echo 'ADDON_TESTS_RESULTS;NOTRUN' >> $RESULTS_FILE
fi

#
# Duplicate checks
#
if [ "X$DO_DUPLICATE_CHECKS" = Xtrue -a "$ONLY_FIREWORKS" = false ]; then
  pushd $CMSSW_BASE/src
  eval `scram run -sh`
  echo '--------------------------------------'
  echo "check dup dicts"
  duplicateReflexLibrarySearch.py --dir ./ --dup 2>&1 | tee -a $WORKSPACE/duplicateChecks.log
  echo "check wrong dict locations"
  duplicateReflexLibrarySearch.py --dir ./ --lostDefs 2>&1 | tee -a $WORKSPACE/duplicateChecks.log
  echo "check dup plugins"
  duplicateReflexLibrarySearch.py   --edmPD 2>&1 | tee -a $WORKSPACE/duplicateChecks.log
  echo '--------------------------------------'
  popd
fi

#
# Valgrind tests
#
for WF in ${WORKFLOWS_FOR_VALGRIND_TEST//,/ }; do 
  $WORKSPACE/cms-bot/report-pull-request-results TESTS_RUNNING --pr $PULL_REQUEST_NUMBER -c $LAST_COMMIT --pr-job-id ${BUILD_NUMBER} --add-message "Running Valgrind" $DRY_RUN

  echo 'I will run valgrind for the following workflow'
  echo $WF; 
  mkdir -p "$WORKSPACE/valgrindResults-"$WF
  pushd "$WORKSPACE/valgrindResults-"$WF
  runTheMatrix.py --command '-n 10 --prefix "time valgrind --tool=memcheck --suppressions=$CMSSW_RELEASE_BASE/src/Utilities/ReleaseScripts/data/cms-valgrind-memcheck.supp --num-callers=20 --xml=yes --xml-file=valgrind.xml " ' -l $WF  
  popd
done


#evaluate results

if $ALL_OK ; then
  echo $ALL_OK
  $WORKSPACE/cms-bot/report-pull-request-results TESTS_OK_PR --pr $PULL_REQUEST_NUMBER -c $LAST_COMMIT --pr-job-id ${BUILD_NUMBER} --recent-merges $RECENT_COMMITS_FILE $DRY_RUN
elif [ "X$BUILD_OK" = Xfalse ]; then
  echo $BUILD_OK
  $WORKSPACE/cms-bot/report-pull-request-results PARSE_BUILD_FAIL --pr $PULL_REQUEST_NUMBER -c $LAST_COMMIT --pr-job-id ${BUILD_NUMBER} --unit-tests-file $WORKSPACE/build.log --recent-merges $RECENT_COMMITS_FILE $DRY_RUN
elif [ "X$UNIT_TESTS_OK" = Xfalse ]; then
  echo $UNIT_TESTS_OK
  echo 'failure in unit tests'
  $WORKSPACE/cms-bot/report-pull-request-results PARSE_UNIT_TESTS_FAIL --pr $PULL_REQUEST_NUMBER -c $LAST_COMMIT --pr-job-id ${BUILD_NUMBER} --unit-tests-file $WORKSPACE/unitTests.log --recent-merges $RECENT_COMMITS_FILE $DRY_RUN
elif [ "X$RELVALS_OK" = Xfalse ]; then
  pushd $WORKSPACE/
  $WORKSPACE/cms-bot/report-pull-request-results PARSE_MATRIX_FAIL --pr $PULL_REQUEST_NUMBER -c $LAST_COMMIT --pr-job-id ${BUILD_NUMBER} --unit-tests-file $WORKSPACE/matrixTests.log --recent-merges $RECENT_COMMITS_FILE $DRY_RUN
  popd
elif [ "X$ADDON_OK" = Xfalse ]; then
  pushd $WORKSPACE/
  $WORKSPACE/cms-bot/report-pull-request-results PARSE_ADDON_FAIL --pr $PULL_REQUEST_NUMBER -c $LAST_COMMIT --pr-job-id ${BUILD_NUMBER} --unit-tests-file $WORKSPACE/addOnTests.log --recent-merges $RECENT_COMMITS_FILE $DRY_RUN
  popd
elif [ "X$CLANG_BUILD_OK" = Xfalse ]; then
  $WORKSPACE/cms-bot/report-pull-request-results PARSE_CLANG_BUILD_FAIL --pr $PULL_REQUEST_NUMBER -c $LAST_COMMIT --pr-job-id ${BUILD_NUMBER} -f $WORKSPACE/buildClang.log --recent-merges $RECENT_COMMITS_FILE $DRY_RUN 
fi

ls 
