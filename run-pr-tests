#!/bin/sh -ex
CMS_BOT_DIR=$(dirname $0)
case $CMS_BOT_DIR in /*) ;; *) CMS_BOT_DIR=$(pwd)/${CMS_BOT_DIR} ;; esac
source $CMS_BOT_DIR/jenkins-artifacts

CMSBUILD_KEY="/build/`whoami`/`whoami`.keytab"
case $NODE_NAME in
  lxplus* ) CMSBUILD_KEY="$CMSBUILD_KEYTAB/cmsbuild.keytab" ;;
esac
voms-proxy-init -valid 24:00 || true

function Jenkins_GetCPU ()
{
  ACTUAL_CPU=$(getconf _NPROCESSORS_ONLN)
  case $NODE_NAME in
    lxplus* ) ACTUAL_CPU=$(echo $ACTUAL_CPU / 2 | bc) ;;
  esac
  if [ "X$1" != "X" ] ; then
    ACTUAL_CPU=$(echo "$ACTUAL_CPU*$1" | bc)
  fi
  echo $ACTUAL_CPU
}
ls /cvmfs/cms-ib.cern.ch || true
if [ ! X`which kinit` = X ]; then
  kinit cmsbuild@CERN.CH -k -t $CMSBUILD_KEY || true
fi

# If a repo to comment on isn't specified use cmssw
if [ "X$PUB_REPO" == X ] || [ "X$PULL_REQUEST" != X ]; then
  PUB_REPO="cms-sw/cmssw"
fi
### this is for triggering the comparison with the baseline
CMSDIST_ONLY=false
if [ "X$PULL_REQUEST" != X ]; then
  PULL_REQUEST_NUMBER=$PULL_REQUEST
  PUB_REPO="cms-sw/cmssw"
else
  # If PULL_REQUEST is empty then we are only testing a CMSDIST PR, take that
  PULL_REQUEST_NUMBER=$CMSDIST_PR
  CMSDIST_ONLY=true
fi
PULL_REQUEST_JOB_ID=${BUILD_NUMBER}
# Do not update twice the comment when testing CMSDIST only PR or also CMSDIST
if [ "X$CMSDIST_PR" = X ] ; then
  $CMS_BOT_DIR/modify_comment.py -r $PUB_REPO -t JENKINS_TEST_URL -m "https://cmssdt.cern.ch/jenkins/job/${JOB_NAME}/${BUILD_NUMBER}/console" $PULL_REQUEST_NUMBER || true
fi
# to not modify the behavior of other scripts that use the AUTO_POST_MESSAGE parameter
if [ "X$AUTO_POST_MESSAGE" != Xtrue ]; then
  DRY_RUN='--no-post'
fi

if [ "X$CMS_GIT_TOOLS_REPO" == X ]; then
  CMS_GIT_TOOLS_REPO="cms-sw"
fi

cd $WORKSPACE
CONFIG_MAP=$CMS_BOT_DIR/config.map
### to know at the end of the tests if everything went ok
ALL_OK=true
BUILD_OK=true
UNIT_TESTS_OK=true
RELVALS_OK=true
ADDON_OK=true
REAL_ARCH=-`cat /proc/cpuinfo | grep vendor_id | head -n 1 | sed "s/.*: //"`
export SCRAM_ARCH=$ARCHITECTURE

COMPARISON_REL=
COMP_QUEUE=$(echo $RELEASE_FORMAT | sed 's|^\(CMSSW_[0-9]*_[0-9]*\)_.*|\1_X|')

#If a CMSSW area already exists use it as it has been prepared by the CMSDIST test script
if [ ! -d CMSSW_* ]; then
  if [[ $RELEASE_FORMAT != *-* ]]; then
    RELEASE_QUEUE=$RELEASE_FORMAT
    COMP_ARCH=$COMPARISON_ARCH
    if [ "X$COMP_ARCH" = "X" ] ; then
      COMP_ARCH=$(cat $CONFIG_MAP | grep $COMP_QUEUE | grep -v "DISABLED=1" | grep "PROD_ARCH=1" | cut -d ";" -f 1 | cut -d "=" -f 2)
      if [ "X$COMP_ARCH" = "X" ] ; then COMP_ARCH=$ARCHITECTURE ; fi
    fi
    for SCRAM_REL in $(scram -a $SCRAM_ARCH l -c $RELEASE_FORMAT | grep -v -f "$CMS_BOT_DIR/ignore-releases-for-tests" | awk '{print $2}' | sort -r) ;  do
      COMP_REL=$(echo $SCRAM_REL | sed 's|^\(CMSSW_[0-9]*_[0-9]*\)_[^0-9]*\(_X_.*\)|\1\2|')
      has_jenkins_artifacts ib-baseline-tests/$COMP_REL/$COMP_ARCH/$REAL_ARCH/matrix-results/wf_errors.txt || continue
      RELEASE_FORMAT=$SCRAM_REL
      COMPARISON_ARCH=$COMP_ARCH
      COMPARISON_REL=$COMP_REL
      break
    done
    if [ "$RELEASE_FORMAT" = "$RELEASE_QUEUE" ] ; then
      RELEASE_FORMAT=$(scram -a $SCRAM_ARCH l -c $RELEASE_QUEUE | grep -v -f "$CMS_BOT_DIR/ignore-releases-for-tests" | awk '{print $2}' | sort -r | head -1)
      if [ "X$RELEASE_FORMAT" = "X" ] ; then
        $CMS_BOT_DIR/report-pull-request-results RELEASE_NOT_FOUND --repo $PUB_REPO --pr $PULL_REQUEST_NUMBER --pr-job-id ${BUILD_NUMBER} $DRY_RUN
        exit 0
      fi
    fi
  else
    RELEASE_QUEUE=`$CMS_BOT_DIR/get-pr-branch $PULL_REQUEST`
  fi
else
  RELEASE_FORMAT=$( find $WORKSPACE -maxdepth 1 -name "CMSSW_*" -printf '%f\n' )
  RELEASE_QUEUE=$( echo $RELEASE_FORMAT | sed 's|_X.*|_X|' )
fi
[ "X$COMP_QUEUE" = "X" ] && COMP_QUEUE=$RELEASE_QUEUE

if [ "X$COMPARISON_REL" = "X" ] ; then
  COMPARISON_REL=$(echo $RELEASE_FORMAT | sed 's|^\(CMSSW_[0-9]*_[0-9]*\)_[^0-9]*\(_X_.*\)|\1\2|')
fi

if [ "X$COMPARISON_ARCH" = "X" ] ; then
  COMPARISON_ARCH=$(cat $CONFIG_MAP | grep $COMP_QUEUE | grep -v "DISABLED=1" | grep "PROD_ARCH=1" | cut -d ";" -f 1 | cut -d "=" -f 2) #Always take the prod architecture for comparison tests.
  if [ "X$COMPARISON_ARCH" = "X" ] ; then COMPARISON_ARCH=$ARCHITECTURE ; fi
fi

# creation of results summary file
cp $CMS_BOT_DIR/templates/PullRequestSummary.html $WORKSPACE/summary.html
cp $CMS_BOT_DIR/templates/js/renderPRTests.js $WORKSPACE/renderPRTests.js
if [ "X$CMSDIST_ONLY" == Xtrue ]; then
  sed -i 's|https:\/\/github.com\/cms-sw\/cmssw/\pull\/|https:\/\/github.com\/cms-sw\/cmsdist\/pull\/|g' $WORKSPACE/renderPRTests.js
fi
RESULTS_FILE=$WORKSPACE/testsResults.txt
touch $RESULTS_FILE
echo 'PR_NUMBER;'$PULL_REQUEST_NUMBER >> $RESULTS_FILE
echo 'ADDITIONAL_PRS;'$ADDITIONAL_PULL_REQUESTS >> $RESULTS_FILE
echo 'BASE_IB;'$RELEASE_FORMAT >> $RESULTS_FILE
echo 'BUILD_NUMBER;'$BUILD_NUMBER >> $RESULTS_FILE

REQ_OK=$(python -c 'from requests import __version__ as v;x=v.split(".");print int(x[0])*10000+int(x[1])*100+int(x[2])>=20300' 2>/dev/null || echo False)
REQ_OK="False"
if [ "X$REQ_OK" = "XFalse" ] ; then
  pushd $WORKSPACE
    wget --no-check-certificate https://pypi.python.org/packages/source/r/requests/requests-2.3.0.tar.gz#md5=7449ffdc8ec9ac37bbcd286003c80f00
    tar -xvf requests-2.3.0.tar.gz
    sed -i -e 's|^DEFAULT_RETRIES *=.*|DEFAULT_RETRIES=10|' requests-2.3.0/requests/adapters.py
    if [ -z $PYTHONPATH ] ; then 
      export PYTHONPATH=$WORKSPACE/requests-2.3.0
    else
      export PYTHONPATH=$WORKSPACE/requests-2.3.0:$PYTHONPATH
    fi
  popd
fi

case $RELEASE_FORMAT in
  *SLHC*)
     DO_ADDON_TESTS=false
  ;;
esac

if [ ! -d CMSSW_* ]; then
  scram -a $SCRAM_ARCH  project $RELEASE_FORMAT
  cd $RELEASE_FORMAT
else
  cd $WORKSPACE/$RELEASE_FORMAT
fi
$CMS_BOT_DIR/report-pull-request-results TESTS_RUNNING --repo $PUB_REPO --pr $PULL_REQUEST_NUMBER --pr-job-id ${BUILD_NUMBER} --add-message "Test started: $RELEASE_FORMAT for $SCRAM_ARCH" $DRY_RUN
sed -i -e 's|^define  *processTmpMMDData.*|processTmpMMDData=true\ndefine processTmpMMDDataXX|;s|^define  *processMMDData.*|processMMDData=true\ndefine processMMDDataXX|' config/SCRAM/GMake/Makefile.rules
eval $(scram run -sh)
cd src
git config --global --replace-all merge.renamelimit 2500

GIT_MERGE_RESULT_FILE=$WORKSPACE/git-merge-result
RECENT_COMMITS_FILE=$WORKSPACE/git-recent-commits
MB_COMPARISON=NO
touch $RECENT_COMMITS_FILE
# use the branch name if necesary
if [ "X$CMSDIST_ONLY" == Xfalse ]; then # If a CMSSW specific PR was specified
  if [ "X$BRANCH_NAME" = X ]; then
    (git cms-merge-topic -u $PULL_REQUEST && echo 'ALL_OK') 2>&1 | tee -a $GIT_MERGE_RESULT_FILE
  else
    (git cms-merge-topic -u $BRANCH_NAME && echo 'ALL_OK') 2>&1 | tee -a $GIT_MERGE_RESULT_FILE
  fi

  # this is to test several pull requests at the same time
  for PR in ${ADDITIONAL_PULL_REQUESTS//,/ }; do
    echo 'I will add the following pull request to the test'
    echo $PR;
    git cms-merge-topic -u $PR 2>&1 | tee -a $GIT_MERGE_RESULT_FILE
  done

  if grep 'Automatic merge failed' $GIT_MERGE_RESULT_FILE; then
    $CMS_BOT_DIR/report-pull-request-results NOT_MERGEABLE --repo $PUB_REPO --pr $PULL_REQUEST_NUMBER --pr-job-id ${BUILD_NUMBER} $DRY_RUN
    exit 0
  fi

  if grep "Couldn't find remote ref" $GIT_MERGE_RESULT_FILE; then
    echo "Please add the branch name to the parameters"
    $CMS_BOT_DIR/report-pull-request-results REMOTE_REF_ISSUE --repo $PUB_REPO --pr $PULL_REQUEST_NUMBER --pr-job-id ${BUILD_NUMBER} $DRY_RUN
    exit 1
  fi

  git diff --name-only $CMSSW_VERSION > $WORKSPACE/changed-files

  # look for any other error in general
  if ! grep "ALL_OK" $GIT_MERGE_RESULT_FILE; then
    echo "There was an error while running git cms-merge-topic"
    $CMS_BOT_DIR/report-pull-request-results GIT_CMS_MERGE_TOPIC_ISSUE --repo $PUB_REPO --pr $PULL_REQUEST_NUMBER --pr-job-id ${BUILD_NUMBER} $DRY_RUN
    exit 0
  fi

  #############################################
  # Check if there are unwanted commits that came with the merge.
  ############################################
  RECENT_COMMITS_LOG_FILE=$WORKSPACE/git-log-recent-commits
  IB_DATE=`echo $RELEASE_FORMAT | sed -e 's/^.*_//g'`
  YEAR_MONTH_DAY=`echo $IB_DATE | sed -e 's/-[0-9]*$//g'`
  HOUR=`echo $IB_DATE | sed -e "s/$YEAR_MONTH_DAY-//g" | sed -e 's/0*//g'`
  git rev-list --after="$YEAR_MONTH_DAY $HOUR:00" HEAD --merges 2>&1 | tee -a $RECENT_COMMITS_FILE
  git log --after="$YEAR_MONTH_DAY $HOUR:00" HEAD --merges 2>&1 | tee -a $RECENT_COMMITS_LOG_FILE
  if [ $(grep 'Geometry' $WORKSPACE/changed-files | wc -l) -gt 0 ] ; then
    has_jenkins_artifacts material-budget/$RELEASE_FORMAT/$SCRAM_ARCH/Images -d && MB_COMPARISON=YES
  fi
fi

#If Fireworks is the only package involved I only compile and run unit tests
ONLY_FIREWORKS=false
if [ "X$APPLY_FIREWORKS_RULE" = Xtrue ]; then
  ls $WORKSPACE/$RELEASE_FORMAT/src
  NUM_DIRS=$(find $WORKSPACE/$RELEASE_FORMAT/src -mindepth 1 -maxdepth 1 -type d -print | grep -v '.git' | wc -l)
  if [ "$NUM_DIRS" == 1 ]; then
    if [ -d "$WORKSPACE/$RELEASE_FORMAT/src/Fireworks" ] ; then
      ONLY_FIREWORKS=true
      echo 'This pr only involves Fireworks!'
      echo 'Only compiling and running unit tests'
    fi
  fi
fi

# Don't do the following if we are only testing CMSDIST PR
CMSSW_COMMIT=
if [ "X$CMSDIST_ONLY" == Xfalse ]; then
  #get the latest commit and mark it as pending
  LAST_COMMIT=$($CMS_BOT_DIR/process-pull-request -c -r cms-sw/cmssw $PULL_REQUEST)
  if [ "X${LAST_COMMIT}" = "X" ]  ; then
    pushd $WORKSPACE/$RELEASE_FORMAT/src
      if [ "X$BRANCH_NAME" = X ]; then
        LAST_COMMIT=`git log cms-sw/refs/pull/$PULL_REQUEST/head --pretty="%H" | head -n1`
      else
        LAST_COMMIT=`git log ${BRANCH_NAME//:/\/} --pretty="%H" | head -n1`
      fi
    popd
  fi
  CMSSW_COMMIT=$LAST_COMMIT
  $CMS_BOT_DIR/report-pull-request-results TESTS_RUNNING --pr $PULL_REQUEST_NUMBER -c $LAST_COMMIT --pr-job-id ${BUILD_NUMBER} $DRY_RUN

  git log --oneline --merges ${CMSSW_VERSION}..
  $CMS_BOT_DIR/report-pull-request-results TESTS_RUNNING --pr $PULL_REQUEST_NUMBER -c $LAST_COMMIT --pr-job-id ${BUILD_NUMBER} --add-message "Compiling" $DRY_RUN
else
  LAST_COMMIT=$CMSDIST_COMMIT
fi

# #############################################
# test compilation with Clang
# ############################################
echo 'test clang compilation'

NEED_CLANG_TEST=false
if cat $CONFIG_MAP | grep $RELEASE_QUEUE | grep PRS_TEST_CLANG= | grep SCRAM_ARCH=$ARCHITECTURE; then
  NEED_CLANG_TEST=true
fi

if [ "X$TEST_CLANG_COMPILATION" = Xtrue -a $NEED_CLANG_TEST = true -a "X$CMSDIST_PR" = X ]; then
  $CMS_BOT_DIR/report-pull-request-results TESTS_RUNNING --repo $PUB_REPO --pr $PULL_REQUEST_NUMBER -c $LAST_COMMIT --pr-job-id ${BUILD_NUMBER} --add-message "Testing Clang compilation" $DRY_RUN

  #first, add the command to the log
  CLANG_CMD="scram b vclean && scram build -k -j $(Jenkins_GetCPU 2) USER_CXXFLAGS='-fsyntax-only' COMPILER='llvm compile'"
  echo $CLANG_CMD > $WORKSPACE/buildClang.log

  (eval $CLANG_CMD && echo 'ALL_OK') 2>&1 | tee -a $WORKSPACE/buildClang.log

  TEST_ERRORS=`grep -E "^gmake: .* Error [0-9]" $WORKSPACE/buildClang.log` || true
  GENERAL_ERRORS=`grep "ALL_OK" $WORKSPACE/buildClang.log` || true

  if [ "X$TEST_ERRORS" != "X" -o "X$GENERAL_ERRORS" = "X" ]; then
    echo "Errors when testing compilation with clang"
    echo 'CLANG_COMPILATION_RESULTS;ERROR' >> $RESULTS_FILE
    ALL_OK=false
    CLANG_BUILD_OK=false
  else
    echo "the clan compilation had no errors!!"
    echo 'CLANG_COMPILATION_RESULTS;OK' >> $RESULTS_FILE
  fi
else
  echo 'CLANG_COMPILATION_RESULTS;NOTRUN' >> $RESULTS_FILE
fi

#Do QA checks
#Code Rules
QA_RES="NOTRUN"
if [ "X$CMSDIST_ONLY" == "Xfalse" ]; then # If a CMSSW specific PR was specified
  $CMS_BOT_DIR/report-pull-request-results TESTS_RUNNING --repo $PUB_REPO --pr $PULL_REQUEST_NUMBER -c $LAST_COMMIT --pr-job-id ${BUILD_NUMBER} --add-message "Running Code Rules Checks" $DRY_RUN
  mkdir $WORKSPACE/codeRules
  cmsCodeRulesChecker.py -s $WORKSPACE/codeRules -r 1,3 || true
  QA_COUNT=$(cat $WORKSPACE/codeRules/cmsCodeRule*.txt | grep '^/' | sed 's|^/||' | sort | uniq | xargs -i grep '{}' $WORKSPACE/changed-files  | wc -l)
  QA_RES="ERROR"
  if [ "X$QA_COUNT" = "X0" ] ; then QA_RES="OK" ; fi
fi
echo "CODE_RULES;${QA_RES}" >> $RESULTS_FILE

#Duplicate dict
QA_RES="NOTRUN"
if [ "X$DO_DUPLICATE_CHECKS" = Xtrue -a "$ONLY_FIREWORKS" = false -a "X$CMSDIST_ONLY" == "Xfalse" ]; then
  $CMS_BOT_DIR/report-pull-request-results TESTS_RUNNING --repo $PUB_REPO --pr $PULL_REQUEST_NUMBER -c $LAST_COMMIT --pr-job-id ${BUILD_NUMBER} --add-message "Running Duplicate Dict Checks" $DRY_RUN
  mkdir $WORKSPACE/dupDict
  QA_RES="OK"
  for type in dup lostDefs edmPD ; do
    duplicateReflexLibrarySearch.py --${type} 2>&1 | grep -v ' SKIPPING ' > $WORKSPACE/dupDict/${type}.txt || true
  done
  QA_COUNT=$(cat $WORKSPACE/dupDict/dup.txt | grep '^  *[.]/[A-Z]' | sed 's|^  *./||' | sort | uniq | xargs -i grep '{}' $WORKSPACE/changed-files  | wc -l)
  if [ "X$QA_COUNT" != "X0" ] ; then QA_RES="ERROR" ; fi
  QA_COUNT=$(cat $WORKSPACE/dupDict/lostDefs.txt | grep '^[.]/[A-Z]' | sed 's|^./||' | sort | uniq | xargs -i grep '{}' $WORKSPACE/changed-files  | wc -l)
  if [ "X$QA_COUNT" != "X0" ] ; then QA_RES="ERROR" ; fi
  if [ -s $WORKSPACE/dupDict/edmPD ] ; then QA_RES="ERROR" ; fi
fi
echo "DUPLICATE_DICT_RULES;${QA_RES}" >> $RESULTS_FILE

#
# Static checks
#
if [ "X$DO_STATIC_CHECKS" = Xtrue -a "$ONLY_FIREWORKS" = false -a "X$CMSDIST_PR" = X ]; then
  $CMS_BOT_DIR/report-pull-request-results TESTS_RUNNING --repo $PUB_REPO --pr $PULL_REQUEST_NUMBER -c $LAST_COMMIT --pr-job-id ${BUILD_NUMBER} --add-message "Running Static Checks" $DRY_RUN
  echo 'STATIC_CHECKS;OK' >> $RESULTS_FILE
  echo '--------------------------------------'
  pushd $WORKSPACE/$RELEASE_FORMAT
  git cms-addpkg Utilities/StaticAnalyzers
  mkdir $WORKSPACE/llvm-analysis
  SCRAM_IGNORE_PACKAGES="Fireworks/% Utilities/StaticAnalyzers" USER_LLVM_CHECKERS="-enable-checker threadsafety -enable-checker cms -disable-checker cms.FunctionDumper" scram b -k -j $(Jenkins_GetCPU 2) checker SCRAM_IGNORE_SUBDIRS=test 2>&1 | tee -a $WORKSPACE/llvm-analysis/runStaticChecks.log
  cp -R $WORKSPACE/$RELEASE_FORMAT/llvm-analysis/*/* $WORKSPACE/llvm-analysis || true
  echo 'END OF STATIC CHECKS'
  echo '--------------------------------------'
  popd
else
  echo 'STATIC_CHECKS;NOTRUN' >> $RESULTS_FILE
fi

scram build clean
git cms-checkdeps -A -a
############################################
# Force the run of DQM tests if necessary
############################################
if ls $WORKSPACE/$RELEASE_FORMAT/src/| grep -i -E "dqm.*|HLTriggerOffline|Validation"; then
  echo "I will make sure that DQM tests will be run"
  if ls $WORKSPACE/$RELEASE_FORMAT/src/| grep "DQMServices"; then
    echo DQMServices is already there
      if ls $WORKSPACE/$RELEASE_FORMAT/src/DQMServices/| grep "Components"; then
        echo "and DQMServices/Components is there"
      else
        git cms-addpkg DQMServices/Components
      fi
  else
    echo "checking out DQMServices"
    git cms-addpkg DQMServices
  fi
fi
#############################################
# Remove poison if asked to do so
#############################################
if [ "X$DISABLE_POISON" = Xtrue ]; then
  if [ -d $WORKSPACE/CMSSW_*/poison ]; then
    rm -rf $WORKSPACE/CMSSW_*/poison
  fi
fi

# #############################################
# test compilation with GCC
# ############################################
$CMS_BOT_DIR/report-pull-request-results TESTS_RUNNING --repo $PUB_REPO --pr $PULL_REQUEST_NUMBER -c $LAST_COMMIT --pr-job-id ${BUILD_NUMBER} --add-message "Running Compilation" $DRY_RUN
COMPILATION_CMD="scram b vclean && scram b -k -j $(Jenkins_GetCPU 2)"
if [ "X$CMSDIST_PR" != X -a $(grep '^edm_checks:' $WORKSPACE/$RELEASE_FORMAT/config/SCRAM/GMake/Makefile.rules | wc -l) -gt 0 ] ; then
  COMPILATION_CMD="scram b vclean && SCRAM_NOEDM_CHECKS=yes scram b -k -j $(Jenkins_GetCPU 2) && scram b -k -j $(Jenkins_GetCPU 2) edm_checks"
fi
echo $COMPILATION_CMD > $WORKSPACE/build.log
(eval $COMPILATION_CMD && echo 'ALL_OK') 2>&1 | tee -a $WORKSPACE/build.log
echo 'END OF BUILD LOG'
echo '--------------------------------------'

TEST_ERRORS=`grep -E "^gmake: .* Error [0-9]" $WORKSPACE/build.log` || true
GENERAL_ERRORS=`grep "ALL_OK" $WORKSPACE/build.log` || true

if [ "X$TEST_ERRORS" != "X" -o "X$GENERAL_ERRORS" = "X" ]; then
    echo "Errors when building"
    echo 'COMPILATION_RESULTS;ERROR' >> $RESULTS_FILE
    ALL_OK=false
    BUILD_OK=false
else
    echo "the build had no errors!!"
    echo 'COMPILATION_RESULTS;OK' >> $RESULTS_FILE
fi

##FIXME: Remove the following das_client.py link once all IBs use das_client wrapper
ln -s `which das_client` $WORKSPACE/$RELEASE_FORMAT/bin/$SCRAM_ARCH/das_client.py
which das_client.py
eval $(scram run -sh)
which das_client.py
#
# Unit tests
#
if [ "X$DO_TESTS" = Xtrue -a "X$BUILD_OK" = Xtrue ]; then
  $CMS_BOT_DIR/report-pull-request-results TESTS_RUNNING --repo $PUB_REPO --pr $PULL_REQUEST_NUMBER -c $LAST_COMMIT --pr-job-id ${BUILD_NUMBER} --add-message "Running Unit Tests" $DRY_RUN
  echo '--------------------------------------'
  UTESTS_CMD="timeout 7200 scram b -k -j $(Jenkins_GetCPU)  runtests "
  echo $UTESTS_CMD > $WORKSPACE/unitTests.log
  (eval $UTESTS_CMD && echo 'ALL_OK') 2>&1 | tee -a $WORKSPACE/unitTests.log
  echo 'END OF UNIT TESTS'
  echo '--------------------------------------'
  #######################################
  # check if DQM Tests where run
  #######################################
  if ls $WORKSPACE/$RELEASE_FORMAT/src/DQMServices/Components/test/ | grep -v -E "[a-z]+"; then 
    echo "DQM Tests were run!"
    pushd $WORKSPACE/$RELEASE_FORMAT/src/DQMServices/Components/test/
    ls | grep -v -E "[a-z]+" | xargs -I ARG mv ARG DQMTestsResults
    mkdir $WORKSPACE/DQMTestsResults
    cp -r DQMTestsResults $WORKSPACE/DQMTestsResults
    ls $WORKSPACE
    popd

    echo 'DQM_TESTS;OK' >> $RESULTS_FILE
  else
    echo 'DQM_TESTS;NOTRUN' >> $RESULTS_FILE
  fi

  TEST_ERRORS=`grep -i "had errors" $WORKSPACE/unitTests.log` || true
  GENERAL_ERRORS=`grep "ALL_OK" $WORKSPACE/unitTests.log` || true

  if [ "X$TEST_ERRORS" != "X" -o "X$GENERAL_ERRORS" = "X" ]; then
    echo "Errors in the unit tests"
    echo 'UNIT_TEST_RESULTS;ERROR' >> $RESULTS_FILE
    ALL_OK=false
    UNIT_TESTS_OK=false
  else
    echo 'UNIT_TEST_RESULTS;OK' >> $RESULTS_FILE
  fi


else

  echo 'UNIT_TEST_RESULTS;NOTRUN' >> $RESULTS_FILE
  echo 'DQM_TESTS;NOTRUN' >> $RESULTS_FILE

fi

#
# Matrix tests
#

JOB_REPORTS=""
if [[ $RELEASE_FORMAT != CMSSW_5_3_X* ]] && [ "X$USE_JOB_REPORTS" = Xtrue ]; then
  JOB_REPORTS='--job-reports'
fi

if [ "X$MATRIX_EXTRAS" = "X" ] ; then
  export MATRIX_EXTRAS=$(grep 'PR_TEST_MATRIX_EXTRAS=' $CMS_BOT_DIR/cmssw-pr-test-config | sed 's|.*=||')
fi

if [ ! "X$MATRIX_EXTRAS" = X ]; then
  MATRIX_EXTRAS="-l `echo $MATRIX_EXTRAS | sed -e 's/[^0-9., ]*//g'`"
fi

if [ "X$DO_SHORT_MATRIX" = Xtrue -a "X$BUILD_OK" = Xtrue -a "$ONLY_FIREWORKS" = false ]; then
  $CMS_BOT_DIR/report-pull-request-results TESTS_RUNNING --repo $PUB_REPO --pr $PULL_REQUEST_NUMBER -c $LAST_COMMIT --pr-job-id ${BUILD_NUMBER} --add-message "Running RelVals" $DRY_RUN
  echo '--------------------------------------'
  mkdir "$WORKSPACE/runTheMatrix-results"
  pushd "$WORKSPACE/runTheMatrix-results"

    case $RELEASE_FORMAT in
        *_THREADED_*)
        THREADED_PARAM='-t 4 --command \"--customise FWCore/Concurrency/dropNonMTSafe.dropNonMTSafe\"'
        ;;
       *)
    esac

    case $RELEASE_FORMAT in
        *SLHCDEV*)
         SLHC_PARAM='-w upgrade'
         WF_LIST="-l 10000,10061,10200,10261,10800,10861,12200,12261,14400,14461,12600,12661,14000,14061,12800,12861,13000,13061,13800,13861"
         ;;
        *SLHC*)
         SLHC_PARAM='-w upgrade'
         WF_LIST="-l 10000,10061,10200,10261,12200,12261,14400,14461,12600,12661,14000,14061,12800,12861,13000,13061,13800,13861"
         ;;
        *)
         WF_LIST="-s $MATRIX_EXTRAS"
        ;;
    esac

    # MATRIX_TIMEOUT is set by jenkins
    dateBefore=$(date +"%s")

    # The --das-options are not correctly interpreted when set as a variable
    EXTRA_RELVALS_OPTION=""
    if [[ $RELEASE_FORMAT != CMSSW_5_3_X* ]] && [ "X$USE_DAS_CACHE" = Xtrue ]; then
      wget --no-check-certificate https://raw.githubusercontent.com/cms-sw/cmsdist/HEAD/das-cache.file
      EXTRA_RELVALS_OPTION='--das-options="--cache das-cache.file --limit 0"'
    fi
    RELVALS_CMD="timeout $MATRIX_TIMEOUT runTheMatrix.py $EXTRA_MATRIX_ARGS $THREADED_PARAM $EXTRA_RELVALS_OPTION $SLHC_PARAM $JOB_REPORTS -j $(Jenkins_GetCPU) $WF_LIST"
    echo $RELVALS_CMD > $WORKSPACE/matrixTests.log
    (eval $RELVALS_CMD && echo 'ALL_OK') 2>&1 | tee -a $WORKSPACE/matrixTests.log
    WORKFLOW_TO_COMPARE=$(grep '^[1-9][0-9]*' $WORKSPACE/matrixTests.log | grep ' Step[0-9]' | sed 's|_.*||' | tr '\n' ',' | sed 's|,$||')

    dateAfter=$(date +"%s")
    diff=$(($dateAfter-$dateBefore))

    if [ "$diff" -ge $MATRIX_TIMEOUT ]; then
      echo "------------"  >> $WORKSPACE/matrixTests.log
      echo 'ERROR TIMEOUT' >> $WORKSPACE/matrixTests.log
    fi

  popd

  TEST_ERRORS=`grep -i -E "ERROR .*" $WORKSPACE/matrixTests.log` || true
  GENERAL_ERRORS=`grep "ALL_OK" $WORKSPACE/matrixTests.log` || true

  if [ "X$TEST_ERRORS" != "X" -o "X$GENERAL_ERRORS" = "X" ]; then
    echo "Errors in the RelVals"

    echo 'MATRIX_TESTS;ERROR' >> $RESULTS_FILE
    echo 'COMPARISON;NOTRUN' >> $RESULTS_FILE

    ALL_OK=false
    RELVALS_OK=false
  else
    echo "no errors in the RelVals!!"
    echo 'MATRIX_TESTS;OK' >> $RESULTS_FILE
    echo 'COMPARISON;QUEUED' >> $RESULTS_FILE

    TRIGGER_COMPARISON_FILE=$WORKSPACE/'comparison.properties'
    echo "Creating properties file $TRIGGER_COMPARISON_FILE"
    echo "RELEASE_FORMAT=$COMPARISON_REL" > $TRIGGER_COMPARISON_FILE
    echo "ARCHITECTURE=${ARCHITECTURE}" >> $TRIGGER_COMPARISON_FILE
    echo "PULL_REQUEST_NUMBER=$PULL_REQUEST_NUMBER" >> $TRIGGER_COMPARISON_FILE
    echo "PULL_REQUEST_JOB_ID=${BUILD_NUMBER}" >> $TRIGGER_COMPARISON_FILE
    echo "REAL_ARCH=$REAL_ARCH" >> $TRIGGER_COMPARISON_FILE
    echo "WORKFLOWS_LIST=${WORKFLOW_TO_COMPARE}" >> $TRIGGER_COMPARISON_FILE
    echo "COMPARISON_ARCH=$COMPARISON_ARCH" >> $TRIGGER_COMPARISON_FILE
    echo "CMSDIST_ONLY=$CMSDIST_ONLY" >> $TRIGGER_COMPARISON_FILE

   #####################################################################
   #### Run igprof
   #####################################################################
   # for now this is only run for 25202

  if [ "X$RUN_IGPROF" = Xtrue ]; then
    echo 'IGPROF;QUEQUED' >> $RESULTS_FILE

    TRIGGER_IGPROF_FILE=$WORKSPACE/'igprof.properties'
    echo "Creating properties file $TRIGGER_IGPROF_FILE"
    echo "RELEASE_FORMAT=$RELEASE_FORMAT" > $TRIGGER_IGPROF_FILE
    echo "ARCHITECTURE=${ARCHITECTURE}" >> $TRIGGER_IGPROF_FILE
    echo "PULL_REQUEST_NUMBER=$PULL_REQUEST_NUMBER" >> $TRIGGER_IGPROF_FILE
    echo "PULL_REQUEST_JOB_ID=${BUILD_NUMBER}" >> $TRIGGER_IGPROF_FILE
    echo "LAST_COMMIT=${LAST_COMMIT}" >> $TRIGGER_IGPROF_FILE
    echo "AUTO_POST_MESSAGE=${AUTO_POST_MESSAGE}" >> $TRIGGER_IGPROF_FILE

  else
    echo 'IGPROF;NOTRUN' >> $RESULTS_FILE
  fi

  #####################################################################
  #### Run cfg-viewer
  #####################################################################

    if [ "X$RUN_CONFIG_VIEWER" = Xtrue ]; then

      mkdir -p "$WORKSPACE/cfg-viewerResults"
      pushd "$WORKSPACE/cfg-viewerResults"
      cfg-viewer.py -r -s "$WORKSPACE/runTheMatrix-results"
      popd
       sed -i "s/<!--CONFIG_FILES_BROWSER//g" $WORKSPACE/summary.html
       sed -i "s/CONFIG_FILES_BROWSER-->//g" $WORKSPACE/summary.html
       sed -i "s/PARAM_CONFIG_BROWSER/https:\/\/cmssdt.cern.ch\/SDT\/jenkins-artifacts\/${JOB_NAME}\/PR-${PULL_REQUEST}\/${BUILD_NUMBER}\/cfg-viewerResults\//g" $WORKSPACE/summary.html
    fi
  fi

else

  echo 'MATRIX_TESTS;NOTRUN' >> $RESULTS_FILE
  echo 'COMPARISON;NOTRUN' >> $RESULTS_FILE
  echo 'IGPROF;NOTRUN' >> $RESULTS_FILE
  if [ "X$CMSDIST_ONLY" == Xfalse ]; then
    ERR_MSG="Build errors/Fireworks only changes/No short matrix requested"
    if [ "X$BUILD_OK" != "Xtrue" ] ; then
      ERR_MSG="Build errors"
    elif [ "X$DO_SHORT_MATRIX" != "Xtrue" ] ; then
      ERR_MSG="short runTheMatrix was not requested"
    elif [ "X$ONLY_FIREWORKS" = "Xtrue" ] ; then
      ERR_MSG="Fireworks only changes in PR"
    fi
    $CMS_BOT_DIR/comment-gh-pr -r $PUB_REPO -p $PULL_REQUEST -m "Comparison not run due to ${ERR_MSG} (RelVals and Igprof tests were also skipped)"
  fi
fi

#
# AddOn Tetss
#
if [ "X$DO_ADDON_TESTS" = Xtrue -a "X$BUILD_OK" = Xtrue ]; then
  $CMS_BOT_DIR/report-pull-request-results TESTS_RUNNING --repo $PUB_REPO --pr $PULL_REQUEST_NUMBER -c $LAST_COMMIT --pr-job-id ${BUILD_NUMBER} --add-message "Running AddOn Tests" $DRY_RUN
  echo '--------------------------------------'
  ADDON_CMD="timeout 5400 addOnTests.py -j $(Jenkins_GetCPU) "
  echo $ADDON_CMD > $WORKSPACE/addOnTests.log
  (eval $ADDON_CMD && echo 'ALL_OK') 2>&1 | tee -a $WORKSPACE/addOnTests.log
  echo 'END OF ADDON TESTS'
  echo '--------------------------------------'
  if [ -d addOnTests ] ; then
    mv addOnTests $WORKSPACE/addOnTests
  fi
  TEST_ERRORS=`grep -i -E ": FAILED .*" $WORKSPACE/addOnTests.log` || true
  GENERAL_ERRORS=`grep "ALL_OK" $WORKSPACE/addOnTests.log` || true

  if [ "X$TEST_ERRORS" != "X" -o "X$GENERAL_ERRORS" = "X" ]; then
    echo "Errors in the addOnTests"
    echo 'ADDON_TESTS;ERROR' >> $RESULTS_FILE
    ALL_OK=false
    ADDON_OK=false
  else
    echo "no errors in the addOnTests!!"
    echo 'ADDON_TESTS;OK' >> $RESULTS_FILE
  fi
else
  echo 'ADDON_TESTS_RESULTS;NOTRUN' >> $RESULTS_FILE
fi

MB_TESTS_OK=NOTRUN
if [ $MB_COMPARISON = "YES" -a "$ALL_OK" = "true" ] ; then
  if has_jenkins_artifacts material-budget/${CMSSW_VERSION}/${SCRAM_ARCH}/Images ; then
    mkdir $WORKSPACE/material-budget
    MB_TESTS_OK=OK
    pushd $WORKSPACE/material-budget
      $CMS_BOT_DIR/run-material-budget || MB_TESTS_OK=ERROR
    popd
  fi
fi
echo "MATERIAL_BUDGET;${MB_TESTS_OK}" >> $RESULTS_FILE

#
# Valgrind tests
#
for WF in ${WORKFLOWS_FOR_VALGRIND_TEST//,/ }; do
  $CMS_BOT_DIR/report-pull-request-results TESTS_RUNNING --pr $PULL_REQUEST_NUMBER -c $LAST_COMMIT --pr-job-id ${BUILD_NUMBER} --add-message "Running Valgrind" $DRY_RUN

  echo 'I will run valgrind for the following workflow'
  echo $WF;
  mkdir -p "$WORKSPACE/valgrindResults-"$WF
  pushd "$WORKSPACE/valgrindResults-"$WF
  runTheMatrix.py --command '-n 10 --prefix "time valgrind --tool=memcheck --suppressions=$CMSSW_RELEASE_BASE/src/Utilities/ReleaseScripts/data/cms-valgrind-memcheck.supp --num-callers=20 --xml=yes --xml-file=valgrind.xml " ' -l $WF
  popd
done

#evaluate results
REPEAT=1
REPORT_PR=$PULL_REQUEST_NUMBER
if [ "X$PULL_REQUEST" == X ]; then
  COMMITS[1]=$CMSDIST_COMMIT
  REPOS[1]="cms-sw/cmsdist"
  PR[1]=$CMSDIST_PR
  REPORT_PR=$CMSDIST_PR
elif [ "X$CMSDIST_PR" != X ]; then
  COMMITS[1]=$CMSSW_COMMIT
  REPOS[1]=$PUB_REPO
  PR[1]=$PULL_REQUEST_NUMBER
  COMMITS[2]=$CMSDIST_COMMIT
  REPOS[2]="cms-sw/cmsdist"
  PR[2]=$CMSDIST_PR
  REPEAT=2
else
  COMMITS[1]=$LAST_COMMIT
  REPOS[1]=$PUB_REPO
  PR[1]=$PULL_REQUEST_NUMBER
fi

TESTS_FAILED="Failed tests:"
if [ "X$BUILD_OK" = Xfalse ]; then
  TESTS_FAILED="$TESTS_FAILED  Build"
fi
if [ "X$UNIT_TESTS_OK" = Xfalse ]; then
  TESTS_FAILED="$TESTS_FAILED  UnitTests"
fi
if [ "X$RELVALS_OK" = Xfalse ]; then
  TESTS_FAILED="$TESTS_FAILED  RelVals"
fi
if [ "X$ADDON_OK" = Xfalse ]; then
  TESTS_FAILED="$TESTS_FAILED  AddOn"
fi
if [ "X$CLANG_BUILD_OK" = Xfalse ]; then
  TESTS_FAILED="$TESTS_FAILED  ClangBuild"
fi

cd $WORKSPACE
mkdir -p upload
for f in runTheMatrix-results llvm-analysis *.log *.html *.txt *.js DQMTestsResults valgrindResults-* cfg-viewerResults igprof-results-data git-merge-result git-log-recent-commits addOnTests codeRules dupDict material-budget; do
  [ -e $f ] && mv $f upload/$f
done
[ -e upload/renderPRTests.js ] && mkdir -p upload/js && mv upload/renderPRTests.js upload/js/
[ -e upload/matrixTests.log  ] && mkdir -p upload/runTheMatrix-results && mv upload/matrixTests.log upload/runTheMatrix-results/
[ -d upload/addOnTests       ] && find upload/addOnTests -name '*.root' -type f | xargs rm -f

rm -f $WORKSPACE/report.txt
for i in $( seq 1 $REPEAT); do
  REPORT_OPTS="--report-pr ${REPORT_PR} --repo ${REPOS[$i]} --pr ${PR[$i]} -c ${COMMITS[$i]} --pr-job-id ${BUILD_NUMBER} --recent-merges $RECENT_COMMITS_FILE $DRY_RUN"
  if $ALL_OK ; then
    REPORT_OPTS[$i]="TESTS_OK_PR ${REPORT_OPTS}"
  else 
    echo "**${TESTS_FAILED}**" >  $WORKSPACE/report.txt
    REPORT_OPTS="--report-file $WORKSPACE/report.txt ${REPORT_OPTS}"
    if [ "X$BUILD_OK" = Xfalse ]; then
      $CMS_BOT_DIR/report-pull-request-results PARSE_BUILD_FAIL       -f $WORKSPACE/upload/build.log ${REPORT_OPTS}
    fi
    if [ "X$UNIT_TESTS_OK" = Xfalse ]; then
      $CMS_BOT_DIR/report-pull-request-results PARSE_UNIT_TESTS_FAIL  -f $WORKSPACE/upload/unitTests.log ${REPORT_OPTS}
    fi
    if [ "X$RELVALS_OK" = Xfalse ]; then
      $CMS_BOT_DIR/report-pull-request-results PARSE_MATRIX_FAIL      -f $WORKSPACE/upload/runTheMatrix-results/matrixTests.log ${REPORT_OPTS}
    fi
    if [ "X$ADDON_OK" = Xfalse ]; then
      $CMS_BOT_DIR/report-pull-request-results PARSE_ADDON_FAIL       -f $WORKSPACE/upload/addOnTests.log ${REPORT_OPTS}
    fi
    if [ "X$CLANG_BUILD_OK" = Xfalse ]; then
      $CMS_BOT_DIR/report-pull-request-results PARSE_CLANG_BUILD_FAIL -f $WORKSPACE/upload/buildClang.log ${REPORT_OPTS}
    fi
    REPORT_OPTS[$i]="REPORT_ERRORS ${REPORT_OPTS}"
  fi
done
rm -f all_done
send_jenkins_artifacts $WORKSPACE/upload pull-request-integration/PR-${PULL_REQUEST_NUMBER}/${BUILD_NUMBER} && touch all_done
if [ -f all_done ] ; then
  rm -f all_done
  for i in $( seq 1 $REPEAT); do
    $CMS_BOT_DIR/report-pull-request-results ${REPORT_OPTS[$i]}
  done
else
  exit 1
fi

