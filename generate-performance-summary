#!/usr/bin/env python
from glob import glob
from commands import getstatusoutput
from xml.sax import parseString, ContentHandler
import argparse
import re
from sys import exit
import sys
import time
import pickle
import struct
import socket

CARBON_SERVER = '0.0.0.0'
CARBON_PORT = 2004

class JobReportHandler(ContentHandler):
  def __init__(self, what, step, architecture, release, workflow, timestamp):
    self.counters = dict((k, "") for k in what)
    self.step = step
    self.architecture = architecture
    self.release = release
    self.workflow = workflow
    self.timestamp = timestamp 
    self.metrics = []

  def startElement(self, name, attrs):
    if name != "Metric":
      return
    
    if not attrs["Name"] in self.counters:
      return
    if "nan" in attrs["Value"]:
      return

    path = ".".join(["IBRelVals", self.architecture, self.release, self.workflow, self.step, attrs["Name"]])
    value = attrs["Value"]
    timestamp = time.mktime(self.timestamp)
    self.metrics.append((path, (timestamp, value)))
    self.counters[attrs["Name"]] = attrs["Value"]

class SchemaDumper(ContentHandler):
  def __init__(self, schema):
    self.schema = schema

  def startElement(self, name, attrs):
    if name != "Metric":
      return
    self.schema.add(attrs["Name"])

IB_BASE_DIR="/afs/cern.ch/cms/sw/ReleaseCandidates"

def chunks(l, n):
  for i in xrange(0, len(l), n):
    yield l[i:i+n]

if __name__ == "__main__":
  parser = argparse.ArgumentParser(description='Extract plot data from IB job reports')
  parser.add_argument('--base-dir', dest='baseDir', default=IB_BASE_DIR,
                      help='Where the logs are located.')
  parser.add_argument('--filter-release', dest='filterRelease', default=".*",
                      help='regexp to filter releases')
  parser.add_argument('--filter-workflows', dest='filterWorkflows', default=".*",
                      help='regexp to filter releases')
  parser.add_argument('what', metavar='KEYS', type=str, nargs='*',
                      help='What to dump from the logs')
  args = parser.parse_args()

  print >> sys.stderr, "Parsing files"
  error, files = getstatusoutput("find %s/slc* -name 'pyRelValMatrixLogs.zip'" % IB_BASE_DIR)
  files = [x for x in files.split("\n") if x]
  schema = set()
  for f in files:
    print >> sys.stderr, f
    architecture = re.sub(".*/((slc|osx|fc)[^/]*)/.*", "\\1", f)
    release = re.sub(".*/(CMSSW_[^/]*)/.*", "\\1", f)
    # Note for a future maintainer, remember to fix it by year 2100.
    date = re.sub(".*/CMSSW_[^/]*(20[0-9][0-9]-[0-1][0-9]-[0-3][0-9]-[0-2][0-9][0-9][0-9]).*", "\\1", f)
    release = release.replace(date,"").strip("_")
    timestamp = time.strptime(date, "%Y-%m-%d-%H%M")
    if not re.match(args.filterRelease, release):
      continue
    error, reports = getstatusoutput("unzip -l %s | grep JobReport | awk '{print $4}'" % f)
    metrics = []
    for r in [x for x in reports.split("\n") if x]:
      cmd = "unzip -p %s %s" % (f, r)
      error, report = getstatusoutput(cmd)
      workflow = re.sub("^([^/]*).*", "\\1", r).replace(".","_")
      if not re.match(args.filterWorkflows, workflow):
        continue
      step = re.sub(".*JobReport([0-9]).*", "step\\1", r)
      if not args.what:
        handler = SchemaDumper(schema)
      else:
        handler = JobReportHandler(args.what, step, architecture, release, workflow, timestamp)
      try:
        parseString(report, handler)
      except:
        continue
      metrics += handler.metrics
      if schema:
        print "\n".join(sorted(schema))
        exit(0)
    if not len(metrics):
      continue
    print "Sending %s metrics." % len(metrics)
    # 100 metrics at the time
    for l in chunks(metrics, 100):
      payload = pickle.dumps(l)
      print len(payload)
      header = struct.pack("!L", len(payload))
      message = header + payload
      sock = socket.socket()
      sock.connect((CARBON_SERVER, CARBON_PORT))
      sock.sendall(message)
      sock.close()
      time.sleep(0.5)
